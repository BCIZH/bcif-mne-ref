# NumPy 内存管理与性能优化

## 1. 内存模型

### 1.1 ndarray 内存结构

NumPy 数组在内存中的组织：

```
┌─────────────────────────────────┐
│     Array Metadata (Header)     │
│  - shape                        │
│  - strides                      │
│  - dtype                        │
│  - flags                        │
│  - data pointer                 │
└─────────────────────────────────┘
          │
          ▼
┌─────────────────────────────────┐
│       Data Buffer               │
│  [element0][element1]...        │
└─────────────────────────────────┘
```

**关键组件**:
```python
import numpy as np

arr = np.array([[1, 2, 3], [4, 5, 6]])

# 元数据
print(arr.shape)      # (2, 3)
print(arr.strides)    # (24, 8) for int64
print(arr.dtype)      # int64
print(arr.flags)      # 各种标志
print(arr.data)       # <memory at 0x...>

# 数据指针
print(arr.__array_interface__['data'])  # (地址, 是否只读)
```

### 1.2 内存布局

#### 1.2.1 C 顺序（行主序）

```python
# C 连续（默认）
arr_c = np.array([[1, 2, 3],
                  [4, 5, 6]], order='C')

# 内存布局: [1, 2, 3, 4, 5, 6]
# 最后一个索引变化最快

print(arr_c.flags['C_CONTIGUOUS'])  # True
print(arr_c.strides)                # (24, 8)
```

#### 1.2.2 Fortran 顺序（列主序）

```python
# Fortran 连续
arr_f = np.array([[1, 2, 3],
                  [4, 5, 6]], order='F')

# 内存布局: [1, 4, 2, 5, 3, 6]
# 第一个索引变化最快

print(arr_f.flags['F_CONTIGUOUS'])  # True
print(arr_f.strides)                # (8, 16)
```

#### 1.2.3 步长（Strides）

步长定义在每个维度上移动一个元素需要跳过的字节数：

```python
arr = np.array([[1, 2, 3],
                [4, 5, 6]], dtype=np.int64)

# C 顺序步长
# 第0维: 跳过整行 = 3 * 8 = 24 字节
# 第1维: 跳过一个元素 = 8 字节
print(arr.strides)  # (24, 8)

# 访问 arr[i, j]
# 内存地址 = base_address + i * 24 + j * 8
```

**自定义步长**（高级）:
```python
from numpy.lib.stride_tricks import as_strided

# 创建滑动窗口视图
arr = np.arange(10)
windowed = as_strided(arr, 
                      shape=(8, 3), 
                      strides=(8, 8))
# 每个窗口大小为3，步长为1
```

### 1.3 视图 vs 拷贝

#### 1.3.1 视图操作（共享内存）

```python
arr = np.array([1, 2, 3, 4, 5])

# 切片创建视图
view = arr[1:4]
view[0] = 99
print(arr)  # [1, 99, 3, 4, 5] - 原数组被修改

# 检查是否共享内存
print(np.shares_memory(arr, view))  # True
print(np.may_share_memory(arr, view))  # True

# 获取基础对象
print(view.base is arr)  # True
```

**常见视图操作**:
```python
arr[1:4]          # 基础切片
arr.T             # 转置
arr.reshape(...)  # reshape（某些情况）
arr.ravel()       # 展平（某些情况）
arr.view()        # 显式视图
```

#### 1.3.2 拷贝操作（新内存）

```python
arr = np.array([1, 2, 3, 4, 5])

# 显式拷贝
copy = arr.copy()
copy[0] = 99
print(arr)  # [1, 2, 3, 4, 5] - 原数组不变

# 检查
print(np.shares_memory(arr, copy))  # False
```

**常见拷贝操作**:
```python
arr.copy()           # 显式拷贝
arr[[1, 2, 3]]       # 花式索引
arr[arr > 2]         # 布尔索引
arr.flatten()        # 展平（总是拷贝）
arr + 0              # 算术操作
np.array(arr)        # 从数组创建
```

#### 1.3.3 检测视图或拷贝

```python
def is_view(arr, other):
    return other.base is arr or (
        other.base is not None and other.base is arr.base
    )

# 或使用
np.shares_memory(arr, other)
```

### 1.4 内存对齐

内存对齐可以提高访问速度：

```python
# 创建对齐的数组
arr = np.zeros(100, dtype=np.float64)
print(arr.flags['ALIGNED'])  # True

# 检查对齐
print(arr.ctypes.data % arr.dtype.alignment)  # 0 表示对齐

# 强制对齐
aligned = np.require(arr, requirements=['A'])  # 'A' = aligned
```

## 2. 内存优化策略

### 2.1 选择合适的数据类型

```python
# 默认（可能浪费内存）
arr_default = np.array([1, 2, 3])  # int64 或 int32

# 优化（如果数据范围允许）
arr_opt = np.array([1, 2, 3], dtype=np.int8)

# 内存节省
print(arr_default.nbytes)  # 24 或 12 字节
print(arr_opt.nbytes)      # 3 字节
```

**类型选择指南**:
```python
# 整数
# 范围 [-128, 127] → int8
# 范围 [-32768, 32767] → int16
# 范围 [-2^31, 2^31-1] → int32
# 范围 [-2^63, 2^63-1] → int64

# 浮点数
# 科学计算通常需要 float64
# 机器学习可以用 float32（节省50%内存）
# 深度学习可以用 float16（节省75%内存，但精度低）
```

### 2.2 原地操作

避免创建临时数组：

```python
# 低效（创建临时数组）
arr = arr + 1
arr = arr * 2

# 高效（原地操作）
arr += 1
arr *= 2

# 或使用 out 参数
np.add(arr, 1, out=arr)
np.multiply(arr, 2, out=arr)
```

### 2.3 避免不必要的拷贝

```python
# 低效
def process(arr):
    arr_copy = arr.copy()  # 不必要的拷贝
    return arr_copy * 2

# 高效
def process(arr):
    return arr * 2  # 自动创建结果数组

# 如果需要修改输入
def process_inplace(arr):
    arr *= 2  # 原地操作
    return arr
```

### 2.4 使用视图而非拷贝

```python
# 低效
subset = arr[100:200].copy()

# 高效（如果不需要修改）
subset = arr[100:200]  # 视图，不复制数据
```

### 2.5 内存映射大文件

对于无法完全加载到内存的数据：

```python
# 创建内存映射文件
fp = np.memmap('large_data.dat', 
               dtype='float32', 
               mode='w+', 
               shape=(1000000, 100))

# 像普通数组一样使用
fp[0, :] = 1.0

# 部分数据会自动分页到磁盘
del fp  # 释放资源
```

### 2.6 删除不需要的数组

```python
# 显式删除大数组
large_arr = np.zeros((10000, 10000))
# ... 使用 large_arr
del large_arr

# 触发垃圾回收（通常不需要）
import gc
gc.collect()
```

### 2.7 使用生成器和迭代器

```python
# 低效（一次性加载所有数据）
data_list = [process(arr[i]) for i in range(1000)]

# 高效（按需处理）
def data_generator(arr):
    for i in range(len(arr)):
        yield process(arr[i])

for item in data_generator(arr):
    # 处理 item
    pass
```

## 3. 性能优化

### 3.1 向量化

避免 Python 循环：

```python
import time

n = 1000000

# 慢（Python 循环）
a = list(range(n))
b = list(range(n))
start = time.time()
c = []
for i in range(n):
    c.append(a[i] + b[i])
print(f"Python loop: {time.time() - start:.3f}s")

# 快（向量化）
a = np.arange(n)
b = np.arange(n)
start = time.time()
c = a + b
print(f"Vectorized: {time.time() - start:.3f}s")
# 通常快 10-100 倍
```

### 3.2 广播

利用广播避免显式循环和内存分配：

```python
# 低效
result = np.zeros((1000, 1000))
for i in range(1000):
    for j in range(1000):
        result[i, j] = arr1[i] + arr2[j]

# 高效（使用广播）
result = arr1[:, np.newaxis] + arr2[np.newaxis, :]
# 或
result = arr1[:, None] + arr2
```

### 3.3 NumPy 表达式优化

```python
# 一般优化
# 避免: a * b + c * d
# 改用: np.einsum 或分步计算

# 减少临时数组
# 避免: (a + b) * (c + d)
temp1 = a + b
temp2 = c + d
result = temp1 * temp2
del temp1, temp2

# 使用 einsum
result = np.einsum('i,j,k->ijk', a, b, c)
```

### 3.4 连续内存访问

```python
# C 连续数组（行主序）
arr_c = np.ascontiguousarray(arr)

# Fortran 连续数组（列主序）
arr_f = np.asfortranarray(arr)

# 按内存顺序迭代（最快）
for elem in arr_c.flat:  # C 顺序迭代
    process(elem)
```

### 3.5 缓存友好的访问模式

```python
arr = np.zeros((1000, 1000))

# 缓存不友好（列访问）
for j in range(1000):
    for i in range(1000):
        arr[i, j] += 1  # 跳跃访问

# 缓存友好（行访问）
for i in range(1000):
    for j in range(1000):
        arr[i, j] += 1  # 连续访问
```

### 3.6 使用编译加速

#### 3.6.1 Numba

```python
from numba import jit

@jit(nopython=True)
def fast_function(x):
    total = 0
    for i in range(len(x)):
        total += x[i] ** 2
    return total

# 首次调用会编译
result = fast_function(np.arange(1000000))
# 后续调用使用编译版本，非常快
```

#### 3.6.2 Cython

```cython
# example.pyx
import numpy as np
cimport numpy as np

def fast_sum(np.ndarray[np.float64_t, ndim=1] arr):
    cdef double total = 0
    cdef int i
    for i in range(arr.shape[0]):
        total += arr[i]
    return total
```

### 3.7 并行计算

```python
# 使用 NumPy 的多线程（通过 BLAS）
import threadpoolctl

with threadpoolctl.threadpool_limits(limits=4):
    result = np.dot(large_matrix1, large_matrix2)

# 或使用 joblib
from joblib import Parallel, delayed

def process_chunk(chunk):
    return np.sum(chunk)

results = Parallel(n_jobs=4)(
    delayed(process_chunk)(arr[i:i+100]) 
    for i in range(0, len(arr), 100)
)
```

### 3.8 einsum 优化

```python
# 矩阵乘法
# 低效
result = np.dot(A, B)

# 更灵活
result = np.einsum('ij,jk->ik', A, B, optimize=True)

# 批量矩阵乘法
result = np.einsum('bij,bjk->bik', A, B, optimize=True)

# 检查优化路径
path_info = np.einsum_path('ij,jk->ik', A, B, optimize='optimal')
print(path_info[0])
```

## 4. 性能分析

### 4.1 时间测量

```python
import time

# 基础计时
start = time.time()
result = expensive_operation()
print(f"Time: {time.time() - start:.3f}s")

# 更精确的计时
start = time.perf_counter()
result = expensive_operation()
print(f"Time: {time.perf_counter() - start:.6f}s")

# IPython 魔法命令
%timeit expensive_operation()
%time expensive_operation()
```

### 4.2 内存分析

```python
import numpy as np

# 查看数组内存使用
arr = np.zeros((1000, 1000))
print(f"Memory: {arr.nbytes / 1024**2:.2f} MB")

# 使用 memory_profiler
from memory_profiler import profile

@profile
def memory_intensive_function():
    arr = np.zeros((10000, 10000))
    # ...
    return arr
```

### 4.3 性能基准测试

```python
# 使用 pytest-benchmark
def test_my_function(benchmark):
    result = benchmark(my_function, arg1, arg2)
    assert result is not None

# 或使用 timeit
import timeit

time = timeit.timeit(
    'np.sum(arr)', 
    setup='import numpy as np; arr = np.random.rand(10000)',
    number=1000
)
print(f"Average time: {time/1000:.6f}s")
```

## 5. 常见陷阱

### 5.1 意外的拷贝

```python
# 看起来像视图，实际是拷贝
arr = np.array([[1, 2, 3], [4, 5, 6]])
subset = arr[[0, 1], :]  # 花式索引 → 拷贝

# 检查
print(subset.base is None)  # True（拷贝）
```

### 5.2 数据类型不匹配

```python
# 类型提升可能导致内存增加
arr_int = np.array([1, 2, 3], dtype=np.int32)
arr_float = np.array([1.0, 2.0, 3.0], dtype=np.float64)
result = arr_int + arr_float  # 结果是 float64

# 避免
result = arr_int.astype(np.float32) + arr_float.astype(np.float32)
```

### 5.3 广播内存爆炸

```python
# 危险（可能消耗大量内存）
a = np.random.rand(10000, 1)
b = np.random.rand(1, 10000)
result = a + b  # 创建 (10000, 10000) 数组

# 分块处理
chunk_size = 1000
for i in range(0, 10000, chunk_size):
    chunk_result = a[i:i+chunk_size] + b
    # 处理 chunk_result
```

### 5.4 不必要的类型转换

```python
# 避免重复转换
arr = np.random.rand(1000000)
for _ in range(10):
    arr = arr.astype(np.float32)  # 每次都转换
    # ...

# 转换一次
arr = arr.astype(np.float32)
for _ in range(10):
    # ...
```

## 6. 最佳实践总结

### 6.1 内存优化检查清单

- [ ] 使用合适的数据类型（int8/16/32, float32 vs float64）
- [ ] 优先使用视图而非拷贝
- [ ] 使用原地操作（+=, *=）
- [ ] 大文件使用内存映射
- [ ] 及时删除大数组
- [ ] 检查内存布局（C vs Fortran）
- [ ] 避免不必要的广播

### 6.2 性能优化检查清单

- [ ] 使用向量化操作
- [ ] 利用广播机制
- [ ] 使用连续内存访问
- [ ] 考虑使用 einsum
- [ ] 减少临时数组
- [ ] 使用 Numba/Cython 加速关键代码
- [ ] 利用多线程（BLAS）
- [ ] 分析性能瓶颈

### 6.3 调试技巧

```python
# 检查数组属性
def debug_array(arr, name='arr'):
    print(f"{name}:")
    print(f"  shape: {arr.shape}")
    print(f"  dtype: {arr.dtype}")
    print(f"  strides: {arr.strides}")
    print(f"  C-contiguous: {arr.flags['C_CONTIGUOUS']}")
    print(f"  F-contiguous: {arr.flags['F_CONTIGUOUS']}")
    print(f"  memory: {arr.nbytes / 1024**2:.2f} MB")
    print(f"  base: {arr.base is not None}")

debug_array(my_array)
```

---

**相关文档**:
- [02_核心模块详解.md](02_核心模块详解.md)
- [04_数据类型系统.md](04_数据类型系统.md)
- [05_通用函数ufunc.md](05_通用函数ufunc.md)
- [08_最佳实践与常见模式.md](08_最佳实践与常见模式.md)
