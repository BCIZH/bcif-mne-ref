# scikit-learn 模型选择与评估详解

## 1. 简介

模型选择和评估是机器学习工作流程的关键部分。scikit-learn 提供了丰富的工具来帮助选择最佳模型、调整超参数和评估性能。

### 1.1 核心模块

| 模块 | 功能 |
|-----|------|
| `model_selection` | 交叉验证、超参数调优、数据划分 |
| `metrics` | 评估指标（准确率、F1、ROC-AUC等） |
| `inspection` | 模型检查（部分依赖图、排列重要性） |

## 2. model_selection - 模型选择

位置：`sklearn/model_selection/`

### 2.1 数据划分

#### 2.1.1 train_test_split

**最基本的数据划分**：

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,           # 测试集比例
    random_state=42,
    stratify=y,              # 分层采样（保持类别比例）
    shuffle=True
)
```

#### 2.1.2 交叉验证分割器

**K折交叉验证**:
```python
from sklearn.model_selection import KFold, StratifiedKFold

# 普通 K折
kf = KFold(n_splits=5, shuffle=True, random_state=42)

for train_idx, val_idx in kf.split(X):
    X_train, X_val = X[train_idx], X[val_idx]
    y_train, y_val = y[train_idx], y[val_idx]
    # 训练和验证

# 分层 K折（保持类别比例）
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

for train_idx, val_idx in skf.split(X, y):
    # ...
```

**其他分割器**:
```python
from sklearn.model_selection import (
    RepeatedKFold,           # 重复 K折
    LeaveOneOut,             # 留一法
    LeavePOut,               # 留 P 法
    ShuffleSplit,            # 随机划分
    StratifiedShuffleSplit,  # 分层随机划分
    GroupKFold,              # 组 K折
    TimeSeriesSplit          # 时间序列分割
)

# 时间序列交叉验证（保持时间顺序）
tscv = TimeSeriesSplit(n_splits=5)

for train_idx, val_idx in tscv.split(X):
    # 训练集在前，验证集在后
    pass
```

### 2.2 交叉验证

#### 2.2.1 cross_val_score

**最简单的交叉验证**：

```python
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier

clf = RandomForestClassifier(n_estimators=100, random_state=42)

# 5折交叉验证
scores = cross_val_score(
    clf, X, y,
    cv=5,                    # 折数或分割器
    scoring='accuracy',      # 评估指标
    n_jobs=-1                # 并行数
)

print(f"Accuracy: {scores.mean():.3f} (+/- {scores.std():.3f})")
```

**常用评估指标**:
- 分类: `'accuracy'`, `'f1'`, `'roc_auc'`, `'precision'`, `'recall'`
- 回归: `'r2'`, `'neg_mean_squared_error'`, `'neg_mean_absolute_error'`

#### 2.2.2 cross_validate

**更详细的交叉验证结果**：

```python
from sklearn.model_selection import cross_validate

results = cross_validate(
    clf, X, y,
    cv=5,
    scoring=['accuracy', 'f1', 'roc_auc'],  # 多个指标
    return_train_score=True,                # 返回训练分数
    return_estimator=True                   # 返回拟合的估计器
)

print(results.keys())
# dict_keys(['fit_time', 'score_time', 'test_accuracy', 'train_accuracy', 
#            'test_f1', 'train_f1', 'test_roc_auc', 'train_roc_auc', 'estimator'])

print(f"Test Accuracy: {results['test_accuracy'].mean():.3f}")
print(f"Train Accuracy: {results['train_accuracy'].mean():.3f}")
```

#### 2.2.3 cross_val_predict

**获取交叉验证的预测结果**：

```python
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import confusion_matrix

# 获取每个样本的预测（在其作为测试集时）
y_pred = cross_val_predict(clf, X, y, cv=5)

# 计算混淆矩阵
cm = confusion_matrix(y, y_pred)
print(cm)
```

### 2.3 超参数调优

#### 2.3.1 GridSearchCV - 网格搜索

**暴力搜索所有参数组合**：

```python
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

# 定义参数网格
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'max_features': ['sqrt', 'log2']
}

# 创建网格搜索
grid_search = GridSearchCV(
    estimator=RandomForestClassifier(random_state=42),
    param_grid=param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=2,
    return_train_score=True
)

# 执行搜索
grid_search.fit(X_train, y_train)

# 最佳参数和分数
print(f"Best params: {grid_search.best_params_}")
print(f"Best CV score: {grid_search.best_score_:.3f}")

# 使用最佳模型
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)

# 查看所有结果
import pandas as pd
results_df = pd.DataFrame(grid_search.cv_results_)
print(results_df[['params', 'mean_test_score', 'std_test_score']].head())
```

#### 2.3.2 RandomizedSearchCV - 随机搜索

**随机采样参数组合**，更高效：

```python
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint, uniform

# 定义参数分布
param_distributions = {
    'n_estimators': randint(50, 300),
    'max_depth': [None] + list(range(10, 50, 5)),
    'min_samples_split': randint(2, 20),
    'max_features': uniform(0.1, 0.9),
}

# 随机搜索
random_search = RandomizedSearchCV(
    estimator=RandomForestClassifier(random_state=42),
    param_distributions=param_distributions,
    n_iter=100,              # 尝试的参数组合数
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42,
    verbose=2
)

random_search.fit(X_train, y_train)
print(f"Best params: {random_search.best_params_}")
```

#### 2.3.3 HalvingGridSearchCV - 连续减半网格搜索

**逐步淘汰表现差的参数组合**：

```python
from sklearn.model_selection import HalvingGridSearchCV

halving_search = HalvingGridSearchCV(
    estimator=RandomForestClassifier(random_state=42),
    param_grid=param_grid,
    factor=3,                # 每次迭代保留 1/factor 的候选
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42
)

halving_search.fit(X_train, y_train)
```

### 2.4 学习曲线

#### 2.4.1 learning_curve

**评估模型是否受益于更多数据**：

```python
from sklearn.model_selection import learning_curve
import matplotlib.pyplot as plt
import numpy as np

train_sizes, train_scores, val_scores = learning_curve(
    clf, X, y,
    train_sizes=np.linspace(0.1, 1.0, 10),  # 训练集大小比例
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)

# 计算均值和标准差
train_mean = train_scores.mean(axis=1)
train_std = train_scores.std(axis=1)
val_mean = val_scores.mean(axis=1)
val_std = val_scores.std(axis=1)

# 绘图
plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_mean, label='Training score')
plt.plot(train_sizes, val_mean, label='Validation score')
plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1)
plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1)
plt.xlabel('Training Set Size')
plt.ylabel('Score')
plt.legend()
plt.title('Learning Curve')
plt.show()
```

**解读**:
- 训练和验证分数都低 → 欠拟合
- 训练分数高，验证分数低 → 过拟合
- 两者都高且接近 → 良好拟合

#### 2.4.2 validation_curve

**评估单个超参数的影响**：

```python
from sklearn.model_selection import validation_curve

param_range = [10, 20, 30, 40, 50, 100, 200]

train_scores, val_scores = validation_curve(
    RandomForestClassifier(random_state=42),
    X, y,
    param_name='n_estimators',
    param_range=param_range,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)

train_mean = train_scores.mean(axis=1)
val_mean = val_scores.mean(axis=1)

plt.plot(param_range, train_mean, label='Training score')
plt.plot(param_range, val_mean, label='Validation score')
plt.xlabel('n_estimators')
plt.ylabel('Score')
plt.legend()
plt.show()
```

## 3. metrics - 评估指标

位置：`sklearn/metrics/`

### 3.1 分类指标

#### 3.1.1 基本指标

```python
from sklearn.metrics import (
    accuracy_score,          # 准确率
    precision_score,         # 精确率
    recall_score,            # 召回率
    f1_score,                # F1分数
    balanced_accuracy_score  # 平衡准确率
)

# 准确率
accuracy = accuracy_score(y_true, y_pred)

# 精确率
precision = precision_score(y_true, y_pred, average='weighted')

# 召回率
recall = recall_score(y_true, y_pred, average='weighted')

# F1分数
f1 = f1_score(y_true, y_pred, average='weighted')
```

**average 参数**（多分类）:
- `'binary'`: 二分类（默认）
- `'micro'`: 全局计算
- `'macro'`: 未加权平均
- `'weighted'`: 加权平均
- `'samples'`: 多标签分类

**公式**:
- 精确率: $Precision = \frac{TP}{TP + FP}$
- 召回率: $Recall = \frac{TP}{TP + FN}$
- F1分数: $F1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}$

#### 3.1.2 混淆矩阵

```python
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

cm = confusion_matrix(y_true, y_pred)
print(cm)

# 可视化
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Class 0', 'Class 1'])
disp.plot()
plt.show()
```

#### 3.1.3 分类报告

```python
from sklearn.metrics import classification_report

report = classification_report(y_true, y_pred, target_names=['Class 0', 'Class 1'])
print(report)

# 输出示例:
#               precision    recall  f1-score   support
#     Class 0       0.85      0.90      0.87       100
#     Class 1       0.88      0.82      0.85        90
#     accuracy                          0.86       190
#    macro avg      0.87      0.86      0.86       190
# weighted avg      0.86      0.86      0.86       190
```

#### 3.1.4 ROC 和 AUC

```python
from sklearn.metrics import roc_curve, roc_auc_score, RocCurveDisplay

# 需要概率预测
y_proba = clf.predict_proba(X_test)[:, 1]

# ROC 曲线
fpr, tpr, thresholds = roc_curve(y_true, y_proba)

# AUC 分数
auc = roc_auc_score(y_true, y_proba)
print(f"AUC: {auc:.3f}")

# 绘图
RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc).plot()
plt.plot([0, 1], [0, 1], 'k--', label='Random')
plt.show()
```

**多分类 ROC**:
```python
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc

# 二值化标签
y_bin = label_binarize(y_true, classes=[0, 1, 2])

# 获取概率
y_proba = clf.predict_proba(X_test)

# 每个类的 ROC 曲线
for i in range(3):
    fpr, tpr, _ = roc_curve(y_bin[:, i], y_proba[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.show()
```

#### 3.1.5 Precision-Recall 曲线

```python
from sklearn.metrics import precision_recall_curve, average_precision_score, PrecisionRecallDisplay

precision, recall, thresholds = precision_recall_curve(y_true, y_proba)
ap = average_precision_score(y_true, y_proba)

PrecisionRecallDisplay(precision=precision, recall=recall, average_precision=ap).plot()
plt.show()
```

#### 3.1.6 对数损失

```python
from sklearn.metrics import log_loss

loss = log_loss(y_true, y_proba)
```

#### 3.1.7 Matthews 相关系数

```python
from sklearn.metrics import matthews_corrcoef

mcc = matthews_corrcoef(y_true, y_pred)  # 范围 [-1, 1]
```

### 3.2 回归指标

#### 3.2.1 基本指标

```python
from sklearn.metrics import (
    mean_squared_error,           # MSE
    mean_absolute_error,          # MAE
    r2_score,                     # R²
    mean_absolute_percentage_error,  # MAPE
    median_absolute_error         # 中位数绝对误差
)

# 均方误差
mse = mean_squared_error(y_true, y_pred)
rmse = np.sqrt(mse)

# 平均绝对误差
mae = mean_absolute_error(y_true, y_pred)

# R² 分数
r2 = r2_score(y_true, y_pred)

# MAPE
mape = mean_absolute_percentage_error(y_true, y_pred)
```

**公式**:
- MSE: $MSE = \frac{1}{n}\sum_{i=1}^n(y_i - \hat{y}_i)^2$
- MAE: $MAE = \frac{1}{n}\sum_{i=1}^n|y_i - \hat{y}_i|$
- R²: $R^2 = 1 - \frac{\sum(y_i - \hat{y}_i)^2}{\sum(y_i - \bar{y})^2}$

#### 3.2.2 预测误差可视化

```python
from sklearn.metrics import PredictionErrorDisplay

# 残差图
PredictionErrorDisplay.from_estimator(model, X_test, y_test, kind='residual_vs_predicted')
plt.show()

# 实际值 vs 预测值
PredictionErrorDisplay.from_estimator(model, X_test, y_test, kind='actual_vs_predicted')
plt.show()
```

### 3.3 聚类指标

```python
from sklearn.metrics import (
    silhouette_score,        # 轮廓系数
    calinski_harabasz_score, # Calinski-Harabasz 指数
    davies_bouldin_score,    # Davies-Bouldin 指数
    adjusted_rand_score,     # 调整兰德指数（需要真实标签）
    normalized_mutual_info_score,  # 归一化互信息（需要真实标签）
    homogeneity_score,       # 同质性（需要真实标签）
    completeness_score,      # 完整性（需要真实标签）
    v_measure_score          # V-measure（需要真实标签）
)

# 不需要真实标签
silhouette = silhouette_score(X, labels)
ch_score = calinski_harabasz_score(X, labels)
db_score = davies_bouldin_score(X, labels)

# 需要真实标签
ari = adjusted_rand_score(y_true, labels)
nmi = normalized_mutual_info_score(y_true, labels)
```

### 3.4 自定义评分函数

```python
from sklearn.metrics import make_scorer

def custom_metric(y_true, y_pred):
    # 自定义逻辑
    return score

# 转换为 scorer
custom_scorer = make_scorer(
    custom_metric,
    greater_is_better=True,  # 分数越大越好
    needs_proba=False        # 是否需要概率预测
)

# 在交叉验证中使用
scores = cross_val_score(clf, X, y, scoring=custom_scorer, cv=5)
```

## 4. inspection - 模型检查

位置：`sklearn/inspection/`

### 4.1 部分依赖图 (Partial Dependence Plot)

**展示特征对预测的影响**：

```python
from sklearn.inspection import PartialDependenceDisplay

# 单个特征
PartialDependenceDisplay.from_estimator(
    model, X, features=[0],  # 特征索引或名称
    kind='average'           # 'average', 'individual', 'both'
)
plt.show()

# 多个特征
PartialDependenceDisplay.from_estimator(
    model, X, features=[0, 1, (0, 1)],  # 单个特征和交互
)
plt.show()
```

### 4.2 排列重要性 (Permutation Importance)

**通过打乱特征值来评估重要性**：

```python
from sklearn.inspection import permutation_importance

result = permutation_importance(
    model, X_test, y_test,
    n_repeats=10,
    random_state=42,
    n_jobs=-1
)

# 重要性分数
importances = result.importances_mean
importances_std = result.importances_std

# 排序
indices = np.argsort(importances)[::-1]

# 绘图
plt.figure(figsize=(10, 6))
plt.bar(range(len(importances)), importances[indices])
plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45)
plt.ylabel('Importance')
plt.title('Permutation Importance')
plt.show()
```

## 5. 实用工作流程

### 5.1 完整的模型选择流程

```python
from sklearn.model_selection import GridSearchCV, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# 1. 数据划分
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# 2. 超参数调优
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5]
}

grid_search = GridSearchCV(
    RandomForestClassifier(random_state=42),
    param_grid, cv=5, scoring='f1_weighted', n_jobs=-1
)
grid_search.fit(X_train, y_train)

# 3. 最佳模型
best_model = grid_search.best_estimator_
print(f"Best params: {grid_search.best_params_}")

# 4. 交叉验证评估
cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='f1_weighted')
print(f"CV F1: {cv_scores.mean():.3f} (+/- {cv_scores.std():.3f})")

# 5. 测试集评估
y_pred = best_model.predict(X_test)
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

# 6. 特征重要性
importances = best_model.feature_importances_
print("Top 10 features:")
for idx in np.argsort(importances)[::-1][:10]:
    print(f"{feature_names[idx]}: {importances[idx]:.4f}")
```

### 5.2 多模型比较

```python
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC

models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'Gradient Boosting': GradientBoostingClassifier(),
    'SVM': SVC()
}

results = {}

for name, model in models.items():
    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
    results[name] = {
        'mean': scores.mean(),
        'std': scores.std()
    }
    print(f"{name}: {scores.mean():.3f} (+/- {scores.std():.3f})")

# 绘制比较图
names = list(results.keys())
means = [results[n]['mean'] for n in names]
stds = [results[n]['std'] for n in names]

plt.figure(figsize=(10, 6))
plt.bar(names, means, yerr=stds)
plt.ylabel('Accuracy')
plt.title('Model Comparison')
plt.xticks(rotation=45)
plt.show()
```

## 6. 最佳实践

### 6.1 避免数据泄漏

```python
# 错误：在划分之前进行特征缩放
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)  # 使用了所有数据
X_train, X_test = train_test_split(X_scaled, ...)

# 正确：使用 Pipeline
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('classifier', RandomForestClassifier())
])

# Pipeline 确保 scaler 只在训练集上拟合
pipeline.fit(X_train, y_train)
y_pred = pipeline.predict(X_test)
```

### 6.2 处理类别不平衡

```python
from sklearn.utils.class_weight import compute_class_weight

# 1. 类权重
class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)
model = RandomForestClassifier(class_weight='balanced')

# 2. 重采样
from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

# 3. 分层采样
X_train, X_test, y_train, y_test = train_test_split(
    X, y, stratify=y, test_size=0.2
)
```

### 6.3 选择合适的评估指标

| 任务 | 推荐指标 | 说明 |
|-----|---------|------|
| 平衡分类 | Accuracy | 类别均衡时使用 |
| 不平衡分类 | F1, ROC-AUC | 关注少数类 |
| 医疗诊断 | Recall | 减少假阴性 |
| 垃圾邮件检测 | Precision | 减少假阳性 |
| 回归 | R², RMSE | R² 解释性好，RMSE 与原始单位一致 |
| 排序 | NDCG, MAP | 推荐系统 |

## 7. 总结

模型选择和评估的关键要点：

1. **数据划分**: 使用分层采样，避免数据泄漏
2. **交叉验证**: 更可靠的性能估计
3. **超参数调优**: GridSearch（小规模）或 RandomizedSearch（大规模）
4. **评估指标**: 根据业务目标选择合适的指标
5. **模型检查**: 使用学习曲线、特征重要性等工具
6. **Pipeline**: 确保预处理步骤的正确性

---

**相关文档**:
- [01_scikit-learn架构总览.md](01_scikit-learn架构总览.md)
- [02_核心基类与API设计.md](02_核心基类与API设计.md)
- [03_监督学习模块.md](03_监督学习模块.md)
- [07_Pipeline与组合器.md](07_Pipeline与组合器.md)
