# SciPy 统计和概率详解

## 1. scipy.stats - 统计函数

### 1.1 简介

`scipy.stats` 是 SciPy 中最大的子模块之一，提供：
- 连续和离散概率分布
- 描述统计
- 统计检验
- 相关性分析
- 核密度估计
- 概率分布拟合

### 1.2 模块结构

```
scipy.stats/
├── 概率分布
│   ├── 连续分布（~100 种）
│   │   ├── norm          # 正态分布
│   │   ├── uniform       # 均匀分布
│   │   ├── expon         # 指数分布
│   │   └── ...
│   │
│   └── 离散分布（~20 种）
│       ├── binom         # 二项分布
│       ├── poisson       # 泊松分布
│       └── ...
│
├── 描述统计
│   ├── describe()        # 汇总统计
│   ├── gmean()           # 几何平均
│   ├── hmean()           # 调和平均
│   └── skew(), kurtosis()
│
├── 统计检验
│   ├── ttest_1samp()     # 单样本 t 检验
│   ├── ttest_ind()       # 独立样本 t 检验
│   ├── ttest_rel()       # 配对样本 t 检验
│   ├── kstest()          # K-S 检验
│   ├── shapiro()         # Shapiro-Wilk 检验
│   └── mannwhitneyu()    # Mann-Whitney U 检验
│
└── 其他
    ├── pearsonr()        # Pearson 相关
    ├── spearmanr()       # Spearman 相关
    ├── linregress()      # 线性回归
    └── gaussian_kde()    # 核密度估计
```

## 2. 概率分布

### 2.1 连续分布

#### 2.1.1 正态分布（高斯分布）

```python
from scipy import stats
import numpy as np
import matplotlib.pyplot as plt

# 创建正态分布对象
# loc: 均值, scale: 标准差
dist = stats.norm(loc=0, scale=1)

# 概率密度函数（PDF）
x = np.linspace(-4, 4, 100)
pdf = dist.pdf(x)

# 累积分布函数（CDF）
cdf = dist.cdf(x)

# 百分位点函数（PPF，CDF 的逆）
percentiles = dist.ppf([0.025, 0.5, 0.975])
print(f"95% 置信区间: [{percentiles[0]:.3f}, {percentiles[2]:.3f}]")

# 生存函数（SF = 1 - CDF）
sf = dist.sf(x)

# 随机采样
samples = dist.rvs(size=1000)

# 统计量
mean = dist.mean()      # 均值
var = dist.var()        # 方差
std = dist.std()        # 标准差
skew = dist.stats(moments='s')  # 偏度
kurt = dist.stats(moments='k')  # 峰度
```

#### 2.1.2 其他常用连续分布

```python
# 均匀分布
uniform = stats.uniform(loc=0, scale=1)  # [0, 1]

# 指数分布
expon = stats.expon(scale=1/2)  # λ = 2

# t 分布
t = stats.t(df=10)  # 自由度 = 10

# 卡方分布
chi2 = stats.chi2(df=5)

# F 分布
f = stats.f(dfn=5, dfd=10)

# Beta 分布
beta = stats.beta(a=2, b=5)

# Gamma 分布
gamma = stats.gamma(a=2, scale=2)

# 对数正态分布
lognorm = stats.lognorm(s=0.5)

# Weibull 分布
weibull = stats.weibull_min(c=1.5)

# Cauchy 分布
cauchy = stats.cauchy()
```

### 2.2 离散分布

#### 2.2.1 二项分布

```python
# 二项分布 B(n, p)
n = 10  # 试验次数
p = 0.5  # 成功概率

binom = stats.binom(n=n, p=p)

# 概率质量函数（PMF）
k = np.arange(0, n+1)
pmf = binom.pmf(k)

# P(X = 5)
prob = binom.pmf(5)

# P(X <= 5)
cumulative = binom.cdf(5)

# 随机采样
samples = binom.rvs(size=1000)
```

#### 2.2.2 其他离散分布

```python
# 泊松分布
poisson = stats.poisson(mu=3)

# 几何分布
geom = stats.geom(p=0.5)

# 负二项分布
nbinom = stats.nbinom(n=5, p=0.5)

# 超几何分布
hypergeom = stats.hypergeom(M=20, n=7, N=12)
# M: 总数, n: 成功数, N: 抽取数

# 多项分布
multinomial = stats.multinomial(n=10, p=[0.2, 0.3, 0.5])
```

### 2.3 分布的操作

```python
# 冻结分布（固定参数）
frozen_norm = stats.norm(loc=0, scale=1)

# 等价于
pdf_value = stats.norm.pdf(x, loc=0, scale=1)
# 或
pdf_value = frozen_norm.pdf(x)

# 拟合分布到数据
data = np.random.normal(loc=5, scale=2, size=1000)
params = stats.norm.fit(data)
print(f"拟合参数: loc={params[0]:.3f}, scale={params[1]:.3f}")

# 矩
moments = frozen_norm.stats(moments='mvsk')  # mean, var, skew, kurtosis
```

## 3. 描述统计

### 3.1 基本统计量

```python
from scipy import stats
import numpy as np

data = np.random.randn(100)

# 综合描述
desc = stats.describe(data)
print(f"样本数: {desc.nobs}")
print(f"最小值/最大值: {desc.minmax}")
print(f"均值: {desc.mean}")
print(f"方差: {desc.variance}")
print(f"偏度: {desc.skewness}")
print(f"峰度: {desc.kurtosis}")

# 单独计算
mean = np.mean(data)
median = np.median(data)
mode_result = stats.mode(data, keepdims=False)
variance = np.var(data, ddof=1)  # 样本方差（除以 n-1）
std = np.std(data, ddof=1)
```

### 3.2 其他统计量

```python
# 几何平均
gmean = stats.gmean(np.abs(data) + 1)  # 需要正数

# 调和平均
hmean = stats.hmean(np.abs(data) + 1)

# 偏度（skewness）
skewness = stats.skew(data)

# 峰度（kurtosis）
kurtosis = stats.kurtosis(data)

# 变异系数
cv = stats.variation(data)

# 分位数
q25 = np.percentile(data, 25)
q50 = np.percentile(data, 50)  # 中位数
q75 = np.percentile(data, 75)

# 或使用 quantile
quantiles = np.quantile(data, [0.25, 0.5, 0.75])
```

### 3.3 标准化和排名

```python
# Z-score 标准化
z_scores = stats.zscore(data)

# 排名
ranks = stats.rankdata(data)

# 排名（处理相同值）
ranks_average = stats.rankdata(data, method='average')
ranks_min = stats.rankdata(data, method='min')
ranks_max = stats.rankdata(data, method='max')
```

## 4. 统计检验

### 4.1 正态性检验

```python
# Shapiro-Wilk 检验
statistic, p_value = stats.shapiro(data)
print(f"Shapiro-Wilk: statistic={statistic:.4f}, p-value={p_value:.4f}")

if p_value > 0.05:
    print("数据可能来自正态分布")
else:
    print("数据可能不是正态分布")

# Kolmogorov-Smirnov 检验
statistic, p_value = stats.kstest(data, 'norm')
print(f"K-S: statistic={statistic:.4f}, p-value={p_value:.4f}")

# Anderson-Darling 检验
result = stats.anderson(data, dist='norm')
print(f"Anderson-Darling: statistic={result.statistic:.4f}")
```

### 4.2 t 检验

#### 4.2.1 单样本 t 检验

检验样本均值是否等于某个值：

```python
# H0: 均值 = 0
data = np.random.randn(50) + 0.5

statistic, p_value = stats.ttest_1samp(data, popmean=0)
print(f"t 统计量: {statistic:.4f}, p-value: {p_value:.4f}")

if p_value < 0.05:
    print("拒绝原假设：均值不等于 0")
```

#### 4.2.2 独立样本 t 检验

检验两个独立样本的均值是否相等：

```python
group1 = np.random.randn(50)
group2 = np.random.randn(50) + 0.5

# 方差齐性假设
statistic, p_value = stats.ttest_ind(group1, group2)

# 不假设方差齐性（Welch's t-test）
statistic, p_value = stats.ttest_ind(group1, group2, equal_var=False)

print(f"t 统计量: {statistic:.4f}, p-value: {p_value:.4f}")
```

#### 4.2.3 配对样本 t 检验

检验配对数据的差异：

```python
before = np.random.randn(30) + 5
after = before + np.random.randn(30) * 0.5 + 0.3

statistic, p_value = stats.ttest_rel(before, after)
print(f"配对 t 检验: t={statistic:.4f}, p={p_value:.4f}")
```

### 4.3 方差分析（ANOVA）

```python
# 单因素方差分析
group1 = np.random.randn(30)
group2 = np.random.randn(30) + 0.5
group3 = np.random.randn(30) + 1.0

f_statistic, p_value = stats.f_oneway(group1, group2, group3)
print(f"F 统计量: {f_statistic:.4f}, p-value: {p_value:.4f}")
```

### 4.4 非参数检验

#### 4.4.1 Mann-Whitney U 检验

**独立样本的非参数版本**：

```python
statistic, p_value = stats.mannwhitneyu(group1, group2)
print(f"Mann-Whitney U: U={statistic:.4f}, p={p_value:.4f}")
```

#### 4.4.2 Wilcoxon 符号秩检验

**配对样本的非参数版本**：

```python
statistic, p_value = stats.wilcoxon(before, after)
print(f"Wilcoxon: W={statistic:.4f}, p={p_value:.4f}")
```

#### 4.4.3 Kruskal-Wallis H 检验

**多组的非参数版本**：

```python
statistic, p_value = stats.kruskal(group1, group2, group3)
print(f"Kruskal-Wallis: H={statistic:.4f}, p={p_value:.4f}")
```

### 4.5 卡方检验

#### 4.5.1 拟合优度检验

```python
# 观察频数
observed = np.array([10, 15, 20, 25])

# 期望频数（均匀分布）
expected = np.array([17.5, 17.5, 17.5, 17.5])

statistic, p_value = stats.chisquare(observed, expected)
print(f"卡方统计量: {statistic:.4f}, p-value: {p_value:.4f}")
```

#### 4.5.2 独立性检验

```python
# 列联表
contingency_table = np.array([[10, 20, 30],
                               [6, 9, 17]])

chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)
print(f"卡方统计量: {chi2:.4f}, p-value: {p_value:.4f}")
print(f"自由度: {dof}")
```

## 5. 相关性分析

### 5.1 Pearson 相关系数

**线性相关**：

```python
x = np.random.randn(100)
y = 2 * x + np.random.randn(100) * 0.5

# Pearson 相关
r, p_value = stats.pearsonr(x, y)
print(f"Pearson r: {r:.4f}, p-value: {p_value:.4f}")
```

### 5.2 Spearman 秩相关

**单调相关（非参数）**：

```python
# Spearman 相关
rho, p_value = stats.spearmanr(x, y)
print(f"Spearman ρ: {rho:.4f}, p-value: {p_value:.4f}")
```

### 5.3 Kendall τ 相关

**基于秩的相关**：

```python
# Kendall τ
tau, p_value = stats.kendalltau(x, y)
print(f"Kendall τ: {tau:.4f}, p-value: {p_value:.4f}")
```

### 5.4 相关矩阵

```python
# 多变量数据
data = np.random.randn(100, 5)

# Pearson 相关矩阵
corr_matrix = np.corrcoef(data.T)

# Spearman 相关矩阵
rho, p_values = stats.spearmanr(data)
```

## 6. 线性回归

```python
from scipy import stats

x = np.random.randn(100)
y = 2.5 * x + 1.3 + np.random.randn(100) * 0.5

# 线性回归
slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)

print(f"斜率: {slope:.4f} ± {std_err:.4f}")
print(f"截距: {intercept:.4f}")
print(f"R²: {r_value**2:.4f}")
print(f"p-value: {p_value:.4f}")

# 预测
y_pred = slope * x + intercept

# 绘图
import matplotlib.pyplot as plt
plt.scatter(x, y, alpha=0.5)
plt.plot(x, y_pred, 'r-', linewidth=2)
plt.xlabel('x')
plt.ylabel('y')
plt.show()
```

## 7. 核密度估计（KDE）

```python
from scipy import stats
import numpy as np

# 数据
data = np.concatenate([np.random.normal(0, 1, 300),
                       np.random.normal(5, 1, 200)])

# 核密度估计
kde = stats.gaussian_kde(data)

# 评估
x_range = np.linspace(-5, 10, 1000)
density = kde(x_range)

# 绘图
plt.hist(data, bins=50, density=True, alpha=0.5)
plt.plot(x_range, density, 'r-', linewidth=2)
plt.show()

# 带宽选择
kde_scott = stats.gaussian_kde(data, bw_method='scott')
kde_silverman = stats.gaussian_kde(data, bw_method='silverman')
kde_custom = stats.gaussian_kde(data, bw_method=0.2)
```

## 8. 置信区间

### 8.1 均值的置信区间

```python
from scipy import stats
import numpy as np

data = np.random.randn(50) + 5

# 方法 1: 使用 t 分布
confidence = 0.95
n = len(data)
mean = np.mean(data)
sem = stats.sem(data)  # 标准误

ci = stats.t.interval(confidence, n-1, loc=mean, scale=sem)
print(f"95% 置信区间: [{ci[0]:.3f}, {ci[1]:.3f}]")

# 方法 2: 直接计算
margin = stats.t.ppf((1 + confidence) / 2, n-1) * sem
ci = (mean - margin, mean + margin)
```

### 8.2 Bootstrap 置信区间

```python
from scipy import stats

def bootstrap_ci(data, statistic=np.mean, n_bootstrap=10000, confidence=0.95):
    """Bootstrap 置信区间"""
    bootstrap_samples = []
    
    for _ in range(n_bootstrap):
        # 有放回抽样
        sample = np.random.choice(data, size=len(data), replace=True)
        bootstrap_samples.append(statistic(sample))
    
    # 百分位法
    alpha = (1 - confidence) / 2
    ci = np.percentile(bootstrap_samples, [alpha * 100, (1 - alpha) * 100])
    
    return ci

data = np.random.randn(50)
ci = bootstrap_ci(data)
print(f"Bootstrap 95% 置信区间: [{ci[0]:.3f}, {ci[1]:.3f}]")
```

## 9. 多元统计

### 9.1 多元正态分布

```python
from scipy import stats

# 均值向量
mean = [0, 1]

# 协方差矩阵
cov = [[1, 0.5],
       [0.5, 2]]

# 创建多元正态分布
mvn = stats.multivariate_normal(mean=mean, cov=cov)

# 生成样本
samples = mvn.rvs(size=1000)

# PDF
x = np.array([0, 1])
pdf_value = mvn.pdf(x)

# 可视化
x1, x2 = np.mgrid[-3:3:0.1, -3:5:0.1]
pos = np.dstack((x1, x2))
pdf_values = mvn.pdf(pos)

plt.contourf(x1, x2, pdf_values, levels=20, cmap='viridis')
plt.colorbar()
plt.show()
```

### 9.2 主成分分析（PCA）

虽然 sklearn 更常用，但也可以用 scipy：

```python
from scipy import linalg
import numpy as np

# 数据矩阵
X = np.random.randn(100, 5)

# 中心化
X_centered = X - np.mean(X, axis=0)

# 协方差矩阵
cov_matrix = np.cov(X_centered.T)

# 特征值分解
eigenvalues, eigenvectors = linalg.eigh(cov_matrix)

# 按特征值降序排序
idx = eigenvalues.argsort()[::-1]
eigenvalues = eigenvalues[idx]
eigenvectors = eigenvectors[:, idx]

# 主成分得分
n_components = 2
principal_components = X_centered @ eigenvectors[:, :n_components]

# 解释方差比
explained_variance_ratio = eigenvalues / eigenvalues.sum()
print(f"前 2 个主成分解释方差: {explained_variance_ratio[:2].sum():.2%}")
```

## 10. 实用案例

### 10.1 A/B 测试

```python
from scipy import stats
import numpy as np

# A 组和 B 组的转化数据
conversions_A = 120  # A 组转化数
total_A = 1000       # A 组总数

conversions_B = 140  # B 组转化数
total_B = 1000       # B 组总数

# 比例检验
count = np.array([conversions_A, conversions_B])
nobs = np.array([total_A, total_B])

stat, p_value = stats.binom_test(conversions_B, total_B, conversions_A/total_A)
print(f"二项检验 p-value: {p_value:.4f}")

# 或使用卡方检验
contingency = np.array([[conversions_A, total_A - conversions_A],
                        [conversions_B, total_B - conversions_B]])

chi2, p_value, dof, expected = stats.chi2_contingency(contingency)
print(f"卡方检验 p-value: {p_value:.4f}")

if p_value < 0.05:
    print("B 组显著优于 A 组")
else:
    print("无显著差异")
```

### 10.2 异常值检测

```python
from scipy import stats
import numpy as np

data = np.random.randn(100)
data = np.append(data, [10, -10])  # 添加异常值

# 方法 1: Z-score 方法
z_scores = np.abs(stats.zscore(data))
outliers = np.where(z_scores > 3)[0]

# 方法 2: IQR 方法
Q1 = np.percentile(data, 25)
Q3 = np.percentile(data, 75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

outliers_iqr = np.where((data < lower_bound) | (data > upper_bound))[0]

print(f"Z-score 异常值: {outliers}")
print(f"IQR 异常值: {outliers_iqr}")
```

### 10.3 分布拟合

```python
from scipy import stats
import numpy as np

# 生成数据
data = np.random.gamma(2, 2, 1000)

# 尝试拟合多个分布
distributions = [stats.gamma, stats.lognorm, stats.expon, stats.weibull_min]
best_dist = None
best_aic = np.inf

for dist in distributions:
    # 拟合
    params = dist.fit(data)
    
    # 对数似然
    log_likelihood = np.sum(dist.logpdf(data, *params))
    
    # AIC (Akaike Information Criterion)
    k = len(params)
    aic = 2 * k - 2 * log_likelihood
    
    print(f"{dist.name}: AIC = {aic:.2f}")
    
    if aic < best_aic:
        best_aic = aic
        best_dist = (dist, params)

print(f"\n最佳分布: {best_dist[0].name}")

# K-S 检验验证
ks_stat, p_value = stats.kstest(data, best_dist[0].name, args=best_dist[1])
print(f"K-S 检验 p-value: {p_value:.4f}")
```

### 10.4 生存分析（简单版）

```python
from scipy import stats
import numpy as np

# 生存时间数据
survival_times = np.random.exponential(scale=10, size=100)

# 拟合指数分布
loc, scale = stats.expon.fit(survival_times)

# 生存函数
t = np.linspace(0, 50, 100)
survival_prob = stats.expon.sf(t, loc=loc, scale=scale)

# 中位生存时间
median_survival = stats.expon.ppf(0.5, loc=loc, scale=scale)
print(f"中位生存时间: {median_survival:.2f}")

# 绘图
plt.plot(t, survival_prob)
plt.xlabel('Time')
plt.ylabel('Survival Probability')
plt.axhline(0.5, color='r', linestyle='--')
plt.axvline(median_survival, color='r', linestyle='--')
plt.show()
```

## 11. 假设检验选择指南

### 11.1 检验选择流程图

```
数据类型？
├── 分类 → 卡方检验
│
└── 数值
    ├── 单样本
    │   ├── 正态？
    │   │   ├── 是 → 单样本 t 检验
    │   │   └── 否 → Wilcoxon 符号秩检验
    │   │
    │   └── 检验分布 → K-S 检验
    │
    ├── 两样本
    │   ├── 配对？
    │   │   ├── 是
    │   │   │   ├── 正态 → 配对 t 检验
    │   │   │   └── 非正态 → Wilcoxon 符号秩检验
    │   │   │
    │   │   └── 否
    │   │       ├── 正态 → 独立 t 检验
    │   │       └── 非正态 → Mann-Whitney U
    │   │
    └── 多样本
        ├── 正态 → ANOVA
        └── 非正态 → Kruskal-Wallis
```

### 11.2 常用检验总结

| 检验 | 用途 | 假设 |
|-----|------|-----|
| t 检验 | 比较均值 | 正态性 |
| ANOVA | 多组均值 | 正态性、方差齐性 |
| Mann-Whitney | 比较中位数 | 无 |
| Wilcoxon | 配对比较 | 无 |
| Kruskal-Wallis | 多组中位数 | 无 |
| 卡方检验 | 分类数据 | 期望频数 ≥ 5 |
| K-S 检验 | 分布拟合 | 无 |
| Shapiro-Wilk | 正态性 | 无 |

## 12. 统计功效和样本量

### 12.1 功效分析

```python
from scipy import stats
import numpy as np

def power_ttest(effect_size, n, alpha=0.05):
    """计算 t 检验的统计功效"""
    # 非中心参数
    ncp = effect_size * np.sqrt(n)
    
    # 临界值
    critical_value = stats.t.ppf(1 - alpha/2, df=n-1)
    
    # 功效
    power = 1 - stats.nct.cdf(critical_value, df=n-1, nc=ncp)
    power += stats.nct.cdf(-critical_value, df=n-1, nc=ncp)
    
    return power

# Cohen's d = 0.5（中等效应）
effect_size = 0.5
sample_sizes = range(10, 201, 10)
powers = [power_ttest(effect_size, n) for n in sample_sizes]

plt.plot(sample_sizes, powers)
plt.axhline(0.8, color='r', linestyle='--', label='80% power')
plt.xlabel('Sample Size')
plt.ylabel('Statistical Power')
plt.legend()
plt.show()
```

## 13. 最佳实践

### 13.1 统计检验

1. **检查假设**（正态性、方差齐性等）
2. **选择合适的检验**
3. **报告效应量**，不只是 p 值
4. **考虑多重比较校正**
5. **使用双侧检验**（除非有明确理由）

### 13.2 数据分析

1. **探索性数据分析**（EDA）在先
2. **可视化**数据和结果
3. **检查异常值**
4. **报告置信区间**
5. **检查统计功效**

## 14. 总结

**scipy.stats** 提供：
- 100+ 概率分布
- 完整的统计检验套件
- 描述统计和推断统计
- 相关性分析
- 分布拟合和检验

**核心功能**：
- 灵活的分布对象（pdf, cdf, ppf, rvs 等）
- 参数和非参数检验
- Bootstrap 和重采样
- 多元统计基础

---

**相关文档**:
- [01_SciPy架构总览.md](01_SciPy架构总览.md)
- [02_线性代数和稀疏矩阵.md](02_线性代数和稀疏矩阵.md)
- [03_优化和求解器.md](03_优化和求解器.md)
- [04_信号和图像处理.md](04_信号和图像处理.md)
