# SciPy 优化和求解器详解

## 1. scipy.optimize - 优化和求根

### 1.1 简介

`scipy.optimize` 提供了多种优化算法，用于：
- 函数最小化/最大化
- 曲线拟合
- 求根（方程求解）
- 线性规划
- 约束优化

### 1.2 模块结构

```
scipy.optimize/
├── 标量优化
│   ├── minimize_scalar()    # 标量函数最小化
│   ├── brent()              # Brent 方法
│   └── golden()             # 黄金分割法
│
├── 多元优化（无约束）
│   ├── minimize()           # 统一接口
│   ├── fmin()               # Nelder-Mead
│   ├── fmin_bfgs()          # BFGS
│   ├── fmin_cg()            # 共轭梯度
│   └── fmin_l_bfgs_b()      # L-BFGS-B
│
├── 约束优化
│   ├── minimize() + constraints
│   ├── linprog()            # 线性规划
│   └── differential_evolution()
│
├── 求根
│   ├── root()               # 多元方程求根
│   ├── fsolve()             # 非线性方程组
│   ├── root_scalar()        # 标量求根
│   └── brentq()             # Brent 法求根
│
└── 曲线拟合
    ├── curve_fit()          # 非线性最小二乘
    ├── least_squares()      # 非线性最小二乘
    └── leastsq()            # 传统接口
```

## 2. 标量函数优化

### 2.1 minimize_scalar - 统一接口

```python
from scipy import optimize
import numpy as np

# 定义目标函数
def f(x):
    return (x - 2) ** 2 + 1

# 最小化（带边界）
result = optimize.minimize_scalar(f, bounds=(0, 4), method='bounded')

print(f"最小值点: {result.x}")
print(f"最小值: {result.fun}")
print(f"迭代次数: {result.nfev}")
```

### 2.2 不同的方法

```python
# Brent 方法（默认，无边界）
result = optimize.minimize_scalar(f, method='brent')

# 黄金分割法（需要边界）
result = optimize.minimize_scalar(f, bounds=(0, 4), method='golden')

# Bounded 方法（有边界）
result = optimize.minimize_scalar(f, bounds=(0, 4), method='bounded')
```

### 2.3 直接使用特定算法

```python
# Brent 方法
xmin = optimize.brent(f)

# 黄金分割法
xmin = optimize.golden(f)

# 带括号的最小化
xmin = optimize.fminbound(f, 0, 4)
```

## 3. 多元函数优化（无约束）

### 3.1 minimize - 统一接口

```python
from scipy import optimize
import numpy as np

# Rosenbrock 函数（测试函数）
def rosenbrock(x):
    return sum(100.0 * (x[1:] - x[:-1]**2)**2 + (1 - x[:-1])**2)

# 初始点
x0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])

# 最小化
result = optimize.minimize(rosenbrock, x0, method='BFGS')

print(f"最优解: {result.x}")
print(f"最优值: {result.fun}")
print(f"是否成功: {result.success}")
print(f"迭代次数: {result.nit}")
```

### 3.2 常用优化方法

#### 3.2.1 Nelder-Mead 单纯形法

**无需梯度**，适合不光滑函数：

```python
# Nelder-Mead（不需要导数）
result = optimize.minimize(rosenbrock, x0, method='Nelder-Mead')

# 或直接使用
result = optimize.fmin(rosenbrock, x0)
```

#### 3.2.2 BFGS 拟牛顿法

**需要梯度**，快速收敛：

```python
# 手动提供梯度
def rosenbrock_grad(x):
    xm = x[1:-1]
    xm_m1 = x[:-2]
    xm_p1 = x[2:]
    grad = np.zeros_like(x)
    grad[1:-1] = 200*(xm - xm_m1**2) - 400*(xm_p1 - xm**2)*xm - 2*(1 - xm)
    grad[0] = -400*x[0]*(x[1] - x[0]**2) - 2*(1 - x[0])
    grad[-1] = 200*(x[-1] - x[-2]**2)
    return grad

# 使用梯度
result = optimize.minimize(rosenbrock, x0, method='BFGS', jac=rosenbrock_grad)

# 自动数值梯度
result = optimize.minimize(rosenbrock, x0, method='BFGS')
```

#### 3.2.3 L-BFGS-B 有界 BFGS

**内存友好**，支持边界约束：

```python
# 边界约束
bounds = [(0, None)] * len(x0)  # x >= 0

result = optimize.minimize(rosenbrock, x0, method='L-BFGS-B', bounds=bounds)
```

#### 3.2.4 共轭梯度法

```python
# 共轭梯度
result = optimize.minimize(rosenbrock, x0, method='CG')
```

#### 3.2.5 Newton-CG 牛顿法

**需要 Hessian** 或 Hessian-vector product：

```python
def rosenbrock_hess(x):
    # Hessian 矩阵
    # ... (实现略)
    pass

result = optimize.minimize(rosenbrock, x0, method='Newton-CG', 
                          jac=rosenbrock_grad, hess=rosenbrock_hess)
```

### 3.3 方法选择指南

| 方法 | 需要梯度 | 需要 Hessian | 适用场景 |
|-----|---------|-------------|---------|
| Nelder-Mead | ✗ | ✗ | 不光滑、低维 |
| Powell | ✗ | ✗ | 无梯度、中等维度 |
| CG | ✓ | ✗ | 大规模 |
| BFGS | ✓ | ✗ | 中小规模、光滑 |
| L-BFGS-B | ✓ | ✗ | 大规模、有边界 |
| Newton-CG | ✓ | ✓ | 高精度 |
| trust-ncg | ✓ | ✓ | 信赖域 |

## 4. 约束优化

### 4.1 线性约束

```python
from scipy.optimize import minimize, LinearConstraint

def objective(x):
    return x[0]**2 + x[1]**2

# 线性约束: A @ x <= b
# 例如: x[0] + x[1] <= 1
A = [[1, 1]]
lb = -np.inf
ub = 1.0
linear_constraint = LinearConstraint(A, lb, ub)

# 初始点
x0 = np.array([0.5, 0.5])

# 优化
result = minimize(objective, x0, method='trust-constr',
                 constraints=[linear_constraint])
```

### 4.2 非线性约束

```python
from scipy.optimize import NonlinearConstraint

# 非线性约束: c(x) = 0
def constraint_func(x):
    return [x[0]**2 + x[1]**2 - 1]  # 单位圆约束

nonlinear_constraint = NonlinearConstraint(constraint_func, 0, 0)

result = minimize(objective, x0, method='trust-constr',
                 constraints=[nonlinear_constraint])
```

### 4.3 简单边界约束

```python
from scipy.optimize import Bounds

# 边界: 0 <= x[i] <= 1
bounds = Bounds([0, 0], [1, 1])

result = minimize(objective, x0, method='L-BFGS-B', bounds=bounds)
```

### 4.4 传统约束语法

```python
# 等式约束: cons['fun'](x) = 0
eq_cons = {'type': 'eq',
           'fun': lambda x: x[0] + x[1] - 1}

# 不等式约束: cons['fun'](x) >= 0
ineq_cons = {'type': 'ineq',
             'fun': lambda x: x[0]**2 + x[1]**2 - 1}

result = minimize(objective, x0, method='SLSQP',
                 constraints=[eq_cons, ineq_cons])
```

## 5. 全局优化

### 5.1 differential_evolution - 差分进化

**全局优化**，不需要梯度：

```python
from scipy.optimize import differential_evolution

# Rastrigin 函数（多峰函数）
def rastrigin(x):
    return 10 * len(x) + sum(x**2 - 10 * np.cos(2 * np.pi * x))

# 边界
bounds = [(-5.12, 5.12)] * 2

# 全局优化
result = differential_evolution(rastrigin, bounds)

print(f"全局最优解: {result.x}")
print(f"全局最优值: {result.fun}")
```

### 5.2 basinhopping - 盆地跳跃

**随机全局优化**：

```python
from scipy.optimize import basinhopping

# 最小化函数
minimizer_kwargs = {"method": "BFGS"}
result = basinhopping(rastrigin, x0=[1, 1], minimizer_kwargs=minimizer_kwargs)
```

### 5.3 shgo - 简化同伦全局优化

```python
from scipy.optimize import shgo

result = shgo(rastrigin, bounds)
```

### 5.4 dual_annealing - 双退火

```python
from scipy.optimize import dual_annealing

result = dual_annealing(rastrigin, bounds)
```

## 6. 曲线拟合

### 6.1 curve_fit - 非线性最小二乘

```python
from scipy.optimize import curve_fit
import numpy as np

# 数据
xdata = np.linspace(0, 4, 50)
ydata = 2.5 * np.sin(1.3 * xdata) + np.random.normal(size=50) * 0.2

# 模型函数
def func(x, a, b):
    return a * np.sin(b * x)

# 拟合
params, covariance = curve_fit(func, xdata, ydata)

print(f"参数: a={params[0]:.3f}, b={params[1]:.3f}")

# 参数不确定性
perr = np.sqrt(np.diag(covariance))
print(f"不确定性: {perr}")
```

### 6.2 带边界和初始猜测

```python
# 初始猜测
p0 = [1.0, 1.0]

# 参数边界
bounds = ([0, 0], [5, 5])  # (lower, upper)

params, covariance = curve_fit(func, xdata, ydata, p0=p0, bounds=bounds)
```

### 6.3 least_squares - 更通用的接口

```python
from scipy.optimize import least_squares

# 残差函数
def residuals(p, x, y):
    return func(x, *p) - y

# 拟合
result = least_squares(residuals, x0=[1, 1], args=(xdata, ydata))
params = result.x
```

## 7. 求根（方程求解）

### 7.1 标量方程

#### 7.1.1 root_scalar - 统一接口

```python
from scipy.optimize import root_scalar

# 方程: f(x) = 0
def f(x):
    return x**3 - 2*x - 5

# Brent 方法（需要括号）
sol = root_scalar(f, bracket=[2, 3], method='brentq')
print(f"根: {sol.root}")

# Newton 方法（需要导数）
def fprime(x):
    return 3*x**2 - 2

sol = root_scalar(f, x0=2, fprime=fprime, method='newton')
```

#### 7.1.2 特定算法

```python
# Brent 方法
root = optimize.brentq(f, 2, 3)

# Newton 法
root = optimize.newton(f, 2, fprime=fprime)

# 割线法（无需导数）
root = optimize.newton(f, 2)
```

### 7.2 非线性方程组

#### 7.2.1 root - 统一接口

```python
from scipy.optimize import root

# 方程组
def equations(x):
    return [x[0]**2 + x[1]**2 - 1,
            x[0] - x[1]]

# 初始猜测
x0 = [1, 1]

# 求解
sol = root(equations, x0, method='hybr')
print(f"解: {sol.x}")
print(f"是否成功: {sol.success}")
```

#### 7.2.2 fsolve - 传统接口

```python
from scipy.optimize import fsolve

# 求解
solution = fsolve(equations, x0)
```

### 7.3 带 Jacobian

```python
def jacobian(x):
    return [[2*x[0], 2*x[1]],
            [1, -1]]

sol = root(equations, x0, jac=jacobian, method='hybr')
```

## 8. 线性规划

### 8.1 linprog - 线性规划

标准形式：
$$\min_x c^T x$$
subject to:
$$A_{ub} x \leq b_{ub}$$
$$A_{eq} x = b_{eq}$$
$$l \leq x \leq u$$

```python
from scipy.optimize import linprog

# 目标函数系数: min -x[0] - 2*x[1]
c = [-1, -2]

# 不等式约束: A_ub @ x <= b_ub
A_ub = [[2, 1],
        [1, 2],
        [1, 0]]
b_ub = [20, 16, 7]

# 变量边界
x_bounds = [(0, None), (0, None)]

# 求解
result = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=x_bounds, method='highs')

print(f"最优解: {result.x}")
print(f"最优值: {result.fun}")
```

## 9. scipy.integrate - 数值积分和微分方程

### 9.1 简介

`scipy.integrate` 提供：
- 数值积分（求积）
- 常微分方程（ODE）求解
- 偏微分方程（PDE）求解

### 9.2 数值积分

#### 9.2.1 一维积分

```python
from scipy import integrate
import numpy as np

# 定义被积函数
def f(x):
    return np.exp(-x**2)

# 定积分: ∫[0,1] f(x) dx
result, error = integrate.quad(f, 0, 1)
print(f"积分值: {result:.6f}, 误差: {error:.2e}")

# 无穷积分: ∫[0,∞] f(x) dx
result, error = integrate.quad(f, 0, np.inf)
```

#### 9.2.2 多维积分

```python
# 二重积分: ∫∫ f(x,y) dx dy
def f(y, x):  # 注意参数顺序！
    return x * y**2

# ∫[0,2] ∫[0,1] x*y^2 dx dy
result, error = integrate.dblquad(f, 0, 2, 0, 1)

# 三重积分
def f(z, y, x):
    return x * y * z

result, error = integrate.tplquad(f, 0, 1, 0, 1, 0, 1)
```

#### 9.2.3 变限积分

```python
# 变限: ∫[x^2, 1] f(y) dy
def gfun(x):  # 下限
    return x**2

def hfun(x):  # 上限
    return 1

result, error = integrate.dblquad(lambda y, x: y, 0, 1, gfun, hfun)
```

#### 9.2.4 固定样本积分

```python
# 已有采样点
x = np.linspace(0, 10, 100)
y = np.sin(x)

# 梯形法则
integral = integrate.trapezoid(y, x)

# Simpson 法则
integral = integrate.simpson(y, x)

# Romberg 积分
integral = integrate.romberg(f, 0, 10)
```

### 9.3 常微分方程（ODE）

#### 9.3.1 solve_ivp - 初值问题

求解 $\frac{dy}{dt} = f(t, y)$，$y(t_0) = y_0$：

```python
from scipy.integrate import solve_ivp

# 定义 ODE: dy/dt = -2y
def exponential_decay(t, y):
    return -2 * y

# 初值
y0 = [1.0]

# 时间跨度
t_span = (0, 5)

# 求解
sol = solve_ivp(exponential_decay, t_span, y0, dense_output=True)

# 在特定时间点求值
t = np.linspace(0, 5, 100)
y = sol.sol(t)

print(f"y(5) = {sol.y[0, -1]:.6f}")
```

#### 9.3.2 耦合 ODE 系统

```python
# Lorenz 系统
def lorenz(t, y, sigma=10, beta=8/3, rho=28):
    x, y, z = y
    return [sigma * (y - x),
            x * (rho - z) - y,
            x * y - beta * z]

# 初值
y0 = [1.0, 1.0, 1.0]

# 求解
sol = solve_ivp(lorenz, (0, 40), y0, method='RK45', dense_output=True)
```

#### 9.3.3 选择求解器

```python
# RK45: 显式 Runge-Kutta（默认）
sol = solve_ivp(f, t_span, y0, method='RK45')

# RK23: 显式 Runge-Kutta 2/3 阶
sol = solve_ivp(f, t_span, y0, method='RK23')

# DOP853: 显式 Runge-Kutta 8 阶
sol = solve_ivp(f, t_span, y0, method='DOP853')

# Radau: 隐式 Runge-Kutta（刚性问题）
sol = solve_ivp(f, t_span, y0, method='Radau')

# BDF: 后向微分公式（刚性问题）
sol = solve_ivp(f, t_span, y0, method='BDF')

# LSODA: 自动切换（刚性/非刚性）
sol = solve_ivp(f, t_span, y0, method='LSODA')
```

#### 9.3.4 事件检测

```python
# 检测 y = 0 的时刻
def event(t, y):
    return y[0]

event.terminal = True  # 停止积分
event.direction = -1   # 仅下降穿越

sol = solve_ivp(f, t_span, y0, events=event)

if len(sol.t_events[0]) > 0:
    print(f"事件发生在 t = {sol.t_events[0][0]}")
```

#### 9.3.5 传统接口 odeint

```python
from scipy.integrate import odeint

# 定义 ODE（参数顺序不同！）
def f(y, t):
    return -2 * y

# 时间点
t = np.linspace(0, 5, 100)

# 求解
y = odeint(f, y0=[1.0], t=t)
```

### 9.4 边值问题

```python
from scipy.integrate import solve_bvp

# 二阶 ODE: y'' + y = 0
def ode(x, y):
    return np.vstack((y[1], -y[0]))

# 边界条件: y(0) = 0, y(π) = 0
def bc(ya, yb):
    return np.array([ya[0], yb[0]])

# 初始网格
x = np.linspace(0, np.pi, 5)
y = np.zeros((2, x.size))

# 求解
sol = solve_bvp(ode, bc, x, y)

# 精细网格上的解
x_plot = np.linspace(0, np.pi, 100)
y_plot = sol.sol(x_plot)[0]
```

## 10. scipy.interpolate - 插值

### 10.1 一维插值

```python
from scipy import interpolate
import numpy as np

# 数据点
x = np.array([0, 1, 2, 3, 4, 5])
y = np.array([0, 1, 4, 9, 16, 25])

# 线性插值
f_linear = interpolate.interp1d(x, y)

# 三次样条插值
f_cubic = interpolate.interp1d(x, y, kind='cubic')

# 使用
x_new = np.linspace(0, 5, 50)
y_linear = f_linear(x_new)
y_cubic = f_cubic(x_new)
```

### 10.2 样条插值

```python
# B-样条插值
tck = interpolate.splrep(x, y, s=0)  # s=0: 插值
y_spline = interpolate.splev(x_new, tck)

# UnivariateSpline
spl = interpolate.UnivariateSpline(x, y, s=0)
y_spline = spl(x_new)
```

### 10.3 二维插值

```python
# 规则网格插值
x = np.arange(0, 5)
y = np.arange(0, 5)
z = np.random.rand(5, 5)

f = interpolate.interp2d(x, y, z, kind='cubic')

# 新点
x_new = np.linspace(0, 4, 20)
y_new = np.linspace(0, 4, 20)
z_new = f(x_new, y_new)
```

### 10.4 散点插值

```python
from scipy.interpolate import griddata

# 散乱数据点
points = np.random.rand(100, 2)
values = np.random.rand(100)

# 目标网格
grid_x, grid_y = np.mgrid[0:1:100j, 0:1:100j]

# 插值
grid_z = griddata(points, values, (grid_x, grid_y), method='cubic')
```

## 11. 实用案例

### 11.1 拟合实验数据

```python
from scipy.optimize import curve_fit
import numpy as np
import matplotlib.pyplot as plt

# 实验数据（带噪声）
xdata = np.linspace(0, 10, 50)
ydata = 3.5 * np.exp(-xdata / 2.5) + np.random.normal(0, 0.2, 50)

# 模型: y = a * exp(-x / b)
def model(x, a, b):
    return a * np.exp(-x / b)

# 拟合
params, cov = curve_fit(model, xdata, ydata)
a_fit, b_fit = params

# 误差
perr = np.sqrt(np.diag(cov))

print(f"a = {a_fit:.3f} ± {perr[0]:.3f}")
print(f"b = {b_fit:.3f} ± {perr[1]:.3f}")
```

### 11.2 求解刚性 ODE

```python
from scipy.integrate import solve_ivp

# Van der Pol 振荡器（刚性）
def van_der_pol(t, y, mu=1000):
    return [y[1], mu * (1 - y[0]**2) * y[1] - y[0]]

# 使用刚性求解器
sol = solve_ivp(van_der_pol, (0, 3000), [2, 0], method='BDF', 
                max_step=1.0)
```

### 11.3 约束优化实例

```python
# 最小化 x^2 + y^2
# 约束: x + y = 1, x >= 0, y >= 0

def objective(x):
    return x[0]**2 + x[1]**2

eq_cons = {'type': 'eq', 'fun': lambda x: x[0] + x[1] - 1}
bounds = [(0, None), (0, None)]

result = optimize.minimize(objective, [0.5, 0.5], method='SLSQP',
                          bounds=bounds, constraints=eq_cons)

print(f"最优解: x={result.x[0]:.3f}, y={result.x[1]:.3f}")
```

## 12. 最佳实践

### 12.1 优化技巧

1. **提供良好的初始猜测**
2. **使用梯度**（如果可用）
3. **标准化变量**（使其量级相似）
4. **设置合适的容差**
5. **检查结果的 `success` 标志**

### 12.2 求解 ODE 技巧

1. **选择合适的求解器**（刚性 vs 非刚性）
2. **设置 `max_step`** 避免跳过重要特征
3. **使用 `dense_output=True`** 获得连续解
4. **利用事件检测**
5. **检查数值稳定性**

## 13. 总结

**scipy.optimize** 提供：
- 多种优化算法（局部、全局）
- 约束优化
- 曲线拟合
- 方程求根

**scipy.integrate** 提供：
- 数值积分
- ODE/BVP 求解
- 多种积分方案

**scipy.interpolate** 提供：
- 1D/2D/nD 插值
- 样条插值
- 散点插值

---

**相关文档**:
- [01_SciPy架构总览.md](01_SciPy架构总览.md)
- [02_线性代数和稀疏矩阵.md](02_线性代数和稀疏矩阵.md)
- [04_信号和图像处理.md](04_信号和图像处理.md)
