# MNE-Python NumPy ä¾èµ–è¯¦ç»†åˆ†æž

> **æ ¸å¿ƒä¾èµ–**: `numpy >= 1.26, < 3`  
> **ä½¿ç”¨é¢‘çŽ‡**: ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ (100%)  
> **è§’è‰²**: æ•°æ®å­˜å‚¨ã€æ•°å­¦è¿ç®—ã€çº¿æ€§ä»£æ•°ã€FFT

---

## ç›®å½•

1. [NumPy åœ¨ MNE ä¸­çš„è§’è‰²](#numpy-åœ¨-mne-ä¸­çš„è§’è‰²)
2. [æ ¸å¿ƒæ¨¡å—ä½¿ç”¨](#æ ¸å¿ƒæ¨¡å—ä½¿ç”¨)
3. [æ•°æ®ç»“æž„è®¾è®¡](#æ•°æ®ç»“æž„è®¾è®¡)
4. [çº¿æ€§ä»£æ•°åº”ç”¨](#çº¿æ€§ä»£æ•°åº”ç”¨)
5. [FFT åº”ç”¨åœºæ™¯](#fft-åº”ç”¨åœºæ™¯)
6. [æ•°å­¦å‡½æ•°ä½¿ç”¨](#æ•°å­¦å‡½æ•°ä½¿ç”¨)
7. [æ€§èƒ½ä¼˜åŒ–æŠ€å·§](#æ€§èƒ½ä¼˜åŒ–æŠ€å·§)
8. [ä»£ç ç¤ºä¾‹](#ä»£ç ç¤ºä¾‹)

---

## NumPy åœ¨ MNE ä¸­çš„è§’è‰²

### 1. æ•°æ®å­˜å‚¨åŸºç¡€

**æ‰€æœ‰ MNE æ•°æ®å¯¹è±¡çš„åº•å±‚éƒ½æ˜¯ NumPy æ•°ç»„**:

```python
# MNE æ ¸å¿ƒå¯¹è±¡å†…éƒ¨ç»“æž„
class Raw(BaseRaw):
    def __init__(self, ...):
        self._data = np.ndarray  # shape: (n_channels, n_times)
        
class Epochs(BaseEpochs):
    def __init__(self, ...):
        self._data = np.ndarray  # shape: (n_epochs, n_channels, n_times)
        
class Evoked(Evoked):
    def __init__(self, ...):
        self.data = np.ndarray  # shape: (n_channels, n_times)
        
class SourceEstimate:
    def __init__(self, ...):
        self.data = np.ndarray  # shape: (n_vertices, n_times)
```

**æ•°æ®æµ**:
```
æ–‡ä»¶è¯»å– â†’ NumPy æ•°ç»„ â†’ ä¿¡å·å¤„ç† â†’ NumPy æ•°ç»„ â†’ å¯è§†åŒ–/ä¿å­˜
```

---

### 2. NumPy æ¨¡å—ä½¿ç”¨ç»Ÿè®¡

| NumPy æ¨¡å— | ä½¿ç”¨æ–‡ä»¶æ•° | ä¸»è¦ç”¨é€” | å…³é”®å‡½æ•° |
|-----------|-----------|---------|---------|
| **æ ¸å¿ƒæ•°ç»„æ“ä½œ** | ~500 | æ•°æ®å¤„ç† | `np.array`, `np.zeros`, `np.ones`, `np.concatenate` |
| **numpy.linalg** | ~150 | çº¿æ€§ä»£æ•° | `np.linalg.norm`, `np.linalg.svd`, `np.linalg.eig` |
| **numpy.fft** | ~80 | é¢‘åŸŸåˆ†æž | `np.fft.rfft`, `np.fft.irfft`, `np.fft.fftfreq` |
| **numpy.random** | ~120 | éšæœºæ•°ç”Ÿæˆ | `np.random.randn`, `np.random.permutation` |
| **numpy.testing** | ~200 | å•å…ƒæµ‹è¯• | `assert_allclose`, `assert_array_equal` |
| **numpy.polynomial** | ~5 | å¤šé¡¹å¼è®¡ç®— | `legendre.legval` (Legendre å¤šé¡¹å¼) |

---

## æ ¸å¿ƒæ¨¡å—ä½¿ç”¨

### 1. æ•°ç»„åˆ›å»ºä¸Žæ“ä½œ

**ä½ç½®**: å‡ ä¹Žæ‰€æœ‰æ¨¡å—

**å¸¸ç”¨å‡½æ•°**:
```python
# åˆ›å»ºæ•°ç»„
np.zeros((n_channels, n_times))      # åˆå§‹åŒ–å…¨é›¶æ•°ç»„
np.ones(shape)                        # å…¨ä¸€æ•°ç»„
np.empty(shape, dtype=np.float64)    # æœªåˆå§‹åŒ–æ•°ç»„(æ€§èƒ½ä¼˜åŒ–)
np.arange(start, stop, step)          # ç­‰å·®æ•°åˆ—
np.linspace(start, stop, num)         # çº¿æ€§ç©ºé—´

# æ•°ç»„æ“ä½œ
np.concatenate([arr1, arr2], axis=0)  # æ‹¼æŽ¥
np.stack([arr1, arr2], axis=0)        # å †å 
np.split(arr, indices_or_sections)    # åˆ†å‰²
np.transpose(arr, axes)               # è½¬ç½®
np.reshape(arr, new_shape)            # é‡å¡‘
arr.ravel()                           # å±•å¹³

# ç´¢å¼•ä¸Žåˆ‡ç‰‡
arr[start:stop:step]                  # åŸºç¡€åˆ‡ç‰‡
arr[indices]                          # ç´¢å¼•æ•°ç»„
arr[mask]                             # å¸ƒå°”æŽ©ç 
np.where(condition, x, y)             # æ¡ä»¶é€‰æ‹©
```

**ç¤ºä¾‹** - `mne/epochs.py`:
```python
def _get_data(self, item=None, ...):
    # ä½¿ç”¨ NumPy ç´¢å¼•æå– epoch æ•°æ®
    data = self._data[item]  # shape: (n_selected, n_channels, n_times)
    
    # ä½¿ç”¨ NumPy æ‹¼æŽ¥
    if self.preload:
        data = np.concatenate([self._data[i] for i in indices], axis=0)
```

---

### 2. numpy.linalg - çº¿æ€§ä»£æ•°

**ä½ç½®**: `mne/rank.py`, `mne/cov.py`, `mne/minimum_norm/`, `mne/beamformer/`

**æ ¸å¿ƒå‡½æ•°ä½¿ç”¨**:

#### 2.1 çŸ©é˜µèŒƒæ•°

```python
# ä½ç½®: mne/rank.py
import numpy as np

def compute_rank(data, tol='auto'):
    """è®¡ç®—æ•°æ®çŸ©é˜µçš„ç§©"""
    # è®¡ç®— Frobenius èŒƒæ•°
    norm = np.linalg.norm(data, 'fro')  
    
    # å¥‡å¼‚å€¼åˆ†è§£
    s = np.linalg.svd(data, compute_uv=False)
    
    # ç¡®å®šç§©
    rank = np.sum(s > tol * s[0])
    return rank
```

**å¸¸ç”¨èŒƒæ•°å‡½æ•°**:
- `np.linalg.norm(x, ord=2)` - å‘é‡ 2-èŒƒæ•° (æ¬§å‡ é‡Œå¾—è·ç¦»)
- `np.linalg.norm(x, ord=1)` - 1-èŒƒæ•° (æ›¼å“ˆé¡¿è·ç¦»)
- `np.linalg.norm(A, 'fro')` - Frobenius èŒƒæ•° (çŸ©é˜µ)

---

#### 2.2 å¥‡å¼‚å€¼åˆ†è§£ (SVD)

```python
# ä½ç½®: mne/utils/linalg.py
def _safe_svd(A, full_matrices=True, **kwargs):
    """å®‰å…¨çš„ SVD è®¡ç®—ï¼Œå¤„ç† NaN å’Œæ— ç©·å€¼"""
    # NumPy SVD
    U, s, Vh = np.linalg.svd(A, full_matrices=full_matrices)
    
    # å¯¹äºŽå¤æ•°çŸ©é˜µï¼Œç¡®ä¿ç‰¹å¾å‘é‡ç›¸ä½ä¸€è‡´
    if np.iscomplexobj(A):
        # è°ƒæ•´ç›¸ä½
        U = U * np.sign(U[0, :])
    
    return U, s, Vh
```

**SVD åº”ç”¨åœºæ™¯**:
- **PCA é™ç»´**: `mne/preprocessing/xdawn.py`
- **ä¼ªé€†è®¡ç®—**: `mne/channels/interpolation.py`
- **ç§©ä¼°è®¡**: `mne/rank.py`
- **åŽ»å™ª**: `mne/preprocessing/maxwell.py`

---

#### 2.3 ç‰¹å¾å€¼åˆ†è§£

```python
# ä½ç½®: mne/decoding/_ged.py
import numpy as np

def _compute_ged(S, R):
    """å¹¿ä¹‰ç‰¹å¾å€¼åˆ†è§£ (Generalized Eigenvalue Decomposition)"""
    # æ ‡å‡†ç‰¹å¾å€¼åˆ†è§£
    evals, evecs = np.linalg.eigh(S)  # å¯¹ç§°çŸ©é˜µ
    
    # æˆ–è€…å¹¿ä¹‰å½¢å¼
    from scipy.linalg import eigh
    evals, evecs = eigh(S, R)  # S evecs = R evecs * evals
    
    return evals, evecs
```

**ç‰¹å¾å€¼åˆ†è§£åº”ç”¨**:
- **ç©ºé—´æ»¤æ³¢å™¨**: CSP, GED
- **åæ–¹å·®å¯¹è§’åŒ–**: `mne/cov.py`
- **æºå®šä½**: eLORETA

---

#### 2.4 çŸ©é˜µæ±‚é€†ä¸Žä¼ªé€†

```python
# ä½ç½®: mne/utils/numerics.py
def _reg_pinv(x, reg=0, rank='full', rcond=1e-15):
    """æ­£åˆ™åŒ–ä¼ªé€†"""
    U, s, Vh = np.linalg.svd(x, full_matrices=False)
    
    # æ­£åˆ™åŒ–å¥‡å¼‚å€¼
    s_inv = 1.0 / (s + reg * s[0])
    
    # è®¡ç®—ä¼ªé€†
    pinv = (Vh.T * s_inv) @ U.T
    
    return pinv
```

**åº”ç”¨åœºæ™¯**:
- **é€šé“æ’å€¼**: `mne/channels/interpolation.py`
- **æ­£å‘æ¨¡åž‹æ±‚é€†**: `mne/forward/`
- **æœ€å°äºŒä¹˜**: `mne/preprocessing/xdawn.py`

---

### 3. numpy.fft - å¿«é€Ÿå‚…é‡Œå¶å˜æ¢

**ä½ç½®**: `mne/filter.py`, `mne/time_frequency/`, `mne/cuda.py`

**æ ¸å¿ƒå‡½æ•°**:

#### 3.1 å®žæ•° FFT (rfft/irfft)

```python
# ä½ç½®: mne/filter.py
import numpy as np

def filter_data_fft(data, sfreq, l_freq, h_freq):
    """ä½¿ç”¨ FFT å®žçŽ°é¢‘åŸŸæ»¤æ³¢"""
    n_times = data.shape[-1]
    
    # å‰å‘ FFT (å®žæ•°è¾“å…¥)
    data_fft = np.fft.rfft(data, n=n_times, axis=-1)
    
    # é¢‘çŽ‡å‘é‡
    freqs = np.fft.rfftfreq(n_times, 1.0 / sfreq)
    
    # æž„å»ºé¢‘åŸŸæ»¤æ³¢å™¨
    mask = (freqs >= l_freq) & (freqs <= h_freq)
    data_fft[..., ~mask] = 0
    
    # é€† FFT
    data_filtered = np.fft.irfft(data_fft, n=n_times, axis=-1)
    
    return data_filtered
```

**rfft vs fft**:
- `rfft`: å®žæ•°è¾“å…¥ â†’ å‡åŠçš„å¤æ•°è¾“å‡º (åˆ©ç”¨å¯¹ç§°æ€§)
- `fft`: å¤æ•°è¾“å…¥ â†’ å®Œæ•´å¤æ•°è¾“å‡º

**æ€§èƒ½**: `rfft` é€Ÿåº¦çº¦ä¸º `fft` çš„ 2 å€

---

#### 3.2 é¢‘çŽ‡å‘é‡ç”Ÿæˆ

```python
# ä½ç½®: mne/time_frequency/_stft.py
def stftfreq(wsize, sfreq=None):
    """STFT é¢‘çŽ‡å‘é‡"""
    from scipy.fft import rfftfreq
    
    # ä½¿ç”¨ SciPy ç‰ˆæœ¬ (ä¸Ž NumPy å…¼å®¹)
    freqs = rfftfreq(wsize, 1.0 / sfreq)
    
    return freqs
```

**ç›¸å…³å‡½æ•°**:
- `np.fft.fftfreq(n, d)` - å®Œæ•´é¢‘çŽ‡å‘é‡
- `np.fft.rfftfreq(n, d)` - å®žæ•° FFT é¢‘çŽ‡å‘é‡
- `np.fft.fftshift(x)` - å°†é›¶é¢‘çŽ‡ç§»åˆ°ä¸­å¿ƒ

---

#### 3.3 FFT åº”ç”¨åœºæ™¯

| åº”ç”¨ | æ¨¡å— | å‡½æ•° | ç”¨é€” |
|------|------|------|------|
| **é¢‘åŸŸæ»¤æ³¢** | `filter.py` | `rfft/irfft` | FIR æ»¤æ³¢å™¨å·ç§¯ |
| **åŠŸçŽ‡è°±å¯†åº¦** | `time_frequency/multitaper.py` | `rfft` | PSD è®¡ç®— |
| **æ—¶é¢‘åˆ†æž** | `time_frequency/_stft.py` | `rfft` | STFT, é¢‘è°±å›¾ |
| **é‡é‡‡æ ·** | `filter.py` | `rfft` | FFT-based é‡é‡‡æ · |
| **CUDA åŠ é€Ÿ** | `cuda.py` | `rfft` | GPU FFT å·ç§¯ |

---

### 4. numpy.random - éšæœºæ•°ç”Ÿæˆ

**ä½ç½®**: `mne/stats/`, `mne/simulation/`, `mne/utils/`

**éšæœºæ•°ç”Ÿæˆå™¨ (RNG) ç®¡ç†**:

```python
# ä½ç½®: mne/utils/check.py
def check_random_state(seed):
    """å°†ç§å­è½¬æ¢ä¸º NumPy RandomState"""
    if seed is None or seed is np.random:
        return np.random.mtrand._rand
    if isinstance(seed, int):
        return np.random.RandomState(seed)
    if isinstance(seed, np.random.RandomState):
        return seed
    raise ValueError(f"Invalid seed: {seed}")
```

**å¸¸ç”¨éšæœºå‡½æ•°**:

```python
# æ­£æ€åˆ†å¸ƒ
rng = np.random.RandomState(42)
noise = rng.randn(n_channels, n_times)  # æ ‡å‡†æ­£æ€

# æŽ’åˆ—ç»„åˆ
perm = rng.permutation(n_samples)  # éšæœºæŽ’åˆ—ç´¢å¼•

# æ•´æ•°éšæœº
idx = rng.randint(0, n_samples, size=n_bootstraps)  # æœ‰æ”¾å›žæŠ½æ ·

# å‡åŒ€åˆ†å¸ƒ
weights = rng.rand(n_features)  # [0, 1) å‡åŒ€åˆ†å¸ƒ
```

**åº”ç”¨**:
- **Permutation Test**: `mne/stats/permutations.py`
- **Bootstrap**: `mne/stats/cluster_level.py`
- **æ•°æ®æ¨¡æ‹Ÿ**: `mne/simulation/`

---

### 5. numpy.testing - å•å…ƒæµ‹è¯•

**ä½ç½®**: æ‰€æœ‰ `tests/` ç›®å½•

**æ ¸å¿ƒæ–­è¨€å‡½æ•°**:

```python
from numpy.testing import (
    assert_allclose,         # æµ®ç‚¹æ•°è¿‘ä¼¼ç›¸ç­‰
    assert_array_equal,      # æ•°ç»„å®Œå…¨ç›¸ç­‰
    assert_array_almost_equal,  # æ•°ç»„è¿‘ä¼¼ç›¸ç­‰ (æ—§å¼)
    assert_array_less,       # æ•°ç»„å…ƒç´ é€ä¸ªæ¯”è¾ƒ <
)

# ç¤ºä¾‹ç”¨æ³•
def test_filter():
    data = np.random.randn(10, 1000)
    filtered = filter_data(data, sfreq=100, l_freq=1, h_freq=40)
    
    # æ£€æŸ¥å½¢çŠ¶
    assert_array_equal(filtered.shape, data.shape)
    
    # æ£€æŸ¥æ•°å€¼ç²¾åº¦
    assert_allclose(filtered.mean(), 0, atol=0.1)
```

**å‚æ•°è¯´æ˜Ž**:
- `rtol`: ç›¸å¯¹å®¹å·® (relative tolerance)
- `atol`: ç»å¯¹å®¹å·® (absolute tolerance)
- `equal_nan`: å°† NaN è§†ä¸ºç›¸ç­‰

---

## æ•°æ®ç»“æž„è®¾è®¡

### 1. MNE æ•°æ®å¯¹è±¡ä¸Ž NumPy æ•°ç»„æ˜ å°„

```python
# Raw å¯¹è±¡
raw._data: np.ndarray
    shape: (n_channels, n_times)
    dtype: np.float64 or np.float32
    layout: C-contiguous (è¡Œä¼˜å…ˆ)

# Epochs å¯¹è±¡  
epochs._data: np.ndarray
    shape: (n_epochs, n_channels, n_times)
    dtype: np.float64
    layout: C-contiguous

# Evoked å¯¹è±¡
evoked.data: np.ndarray
    shape: (n_channels, n_times)
    dtype: np.float64
    layout: C-contiguous

# SourceEstimate å¯¹è±¡
stc.data: np.ndarray
    shape: (n_vertices, n_times)
    dtype: np.float64
    layout: C-contiguous
```

---

### 2. NumPy dtype é€‰æ‹©

**MNE ä½¿ç”¨ç­–ç•¥**:

| æ•°æ®ç±»åž‹ | NumPy dtype | ä½¿ç”¨åœºæ™¯ |
|---------|-------------|---------|
| **EEG/MEG æ•°æ®** | `np.float64` | é«˜ç²¾åº¦éœ€æ±‚ (é»˜è®¤) |
| **å­˜å‚¨ä¼˜åŒ–** | `np.float32` | å‡å°‘å†…å­˜ (å¯é€‰) |
| **æ•´æ•°ç´¢å¼•** | `np.int64` | äº‹ä»¶ç¼–ç ã€ç´¢å¼•æ•°ç»„ |
| **å¸ƒå°”æŽ©ç ** | `np.bool_` | æ•°æ®é€‰æ‹©ã€åé€šé“æ ‡è®° |
| **å¤æ•°** | `np.complex128` | é¢‘åŸŸè¡¨ç¤ºã€Fourier ç³»æ•° |

**ç¤ºä¾‹** - `mne/io/base.py`:
```python
def _read_data(self, dtype=np.float64):
    """è¯»å–æ•°æ®åˆ°æŒ‡å®šç²¾åº¦"""
    data = self._read_raw_data()
    
    # è½¬æ¢ç²¾åº¦ä»¥èŠ‚çœå†…å­˜
    if dtype == np.float32:
        data = data.astype(np.float32, copy=False)
    
    return data
```

---

### 3. å†…å­˜å¸ƒå±€ä¼˜åŒ–

**C-contiguous vs Fortran-contiguous**:

```python
# C-contiguous (è¡Œä¼˜å…ˆ) - MNE é»˜è®¤
arr_c = np.array([[1, 2, 3],
                   [4, 5, 6]], order='C')
# å†…å­˜å¸ƒå±€: [1, 2, 3, 4, 5, 6]

# Fortran-contiguous (åˆ—ä¼˜å…ˆ) - LAPACK åå¥½
arr_f = np.array([[1, 2, 3],
                   [4, 5, 6]], order='F')
# å†…å­˜å¸ƒå±€: [1, 4, 2, 5, 3, 6]
```

**MNE ç­–ç•¥**:
- **æ•°æ®å­˜å‚¨**: C-contiguous (æ²¿æ—¶é—´è½´æ“ä½œé«˜æ•ˆ)
- **LAPACK è°ƒç”¨**: è‡ªåŠ¨è½¬æ¢ä¸º Fortran-contiguous (é¿å…å¤åˆ¶)

**ç¤ºä¾‹** - `mne/utils/linalg.py`:
```python
def _safe_svd(A, **kwargs):
    """ç¡®ä¿è¾“å…¥ä¸º Fortran-contiguous ä»¥æé«˜ LAPACK æ€§èƒ½"""
    if not np.isfortran(A):
        A = np.asfortranarray(A)  # è½¬æ¢ä½†ä¸ä¸€å®šå¤åˆ¶
    
    U, s, Vh = np.linalg.svd(A, **kwargs)
    return U, s, Vh
```

---

## çº¿æ€§ä»£æ•°åº”ç”¨

### 1. åæ–¹å·®çŸ©é˜µè®¡ç®—

**ä½ç½®**: `mne/cov.py`

```python
def _compute_covariance_from_epochs(epochs):
    """è®¡ç®— epochs çš„åæ–¹å·®çŸ©é˜µ"""
    data = epochs.get_data()  # shape: (n_epochs, n_channels, n_times)
    n_epochs, n_channels, n_times = data.shape
    
    # æ–¹æ³• 1: ä½¿ç”¨ NumPy å¹¿æ’­
    data_centered = data - data.mean(axis=2, keepdims=True)
    cov = np.einsum('ijk,ilk->jl', data_centered, data_centered)
    cov /= (n_epochs * n_times - 1)
    
    # æ–¹æ³• 2: ä½¿ç”¨çŸ©é˜µä¹˜æ³• (æ›´å¿«)
    data_flat = data.reshape(n_epochs * n_times, n_channels)
    data_flat -= data_flat.mean(axis=0)
    cov = (data_flat.T @ data_flat) / (data_flat.shape[0] - 1)
    
    return cov
```

**æ€§èƒ½**: `einsum` vs `@` å–å†³äºŽæ•°æ®å¤§å°å’Œå½¢çŠ¶

---

### 2. ç™½åŒ– (Whitening)

**ä½ç½®**: `mne/cov.py`, `mne/preprocessing/ica.py`

```python
def compute_whitener(cov, reg=0.1):
    """è®¡ç®—ç™½åŒ–çŸ©é˜µ"""
    # ç‰¹å¾å€¼åˆ†è§£
    eigvals, eigvecs = np.linalg.eigh(cov)
    
    # æ­£åˆ™åŒ– (é¿å…æ•°å€¼ä¸ç¨³å®š)
    eigvals_reg = eigvals + reg * eigvals.max()
    
    # ç™½åŒ–çŸ©é˜µ: W = V * diag(1/sqrt(lambda)) * V^T
    whitener = eigvecs @ np.diag(1.0 / np.sqrt(eigvals_reg)) @ eigvecs.T
    
    return whitener

def apply_whitening(data, whitener):
    """åº”ç”¨ç™½åŒ–"""
    # data shape: (n_channels, n_times)
    data_white = whitener @ data
    return data_white
```

**åº”ç”¨**:
- **ICA é¢„å¤„ç†**: `mne/preprocessing/ica.py`
- **CSP ç©ºé—´æ»¤æ³¢**: `mne/decoding/csp.py`
- **å™ªå£°å½’ä¸€åŒ–**: `mne/minimum_norm/inverse.py`

---

### 3. çŸ©é˜µåˆ†è§£æŠ€å·§

#### 3.1 Cholesky åˆ†è§£

```python
# ä½ç½®: mne/cov.py
def _regularized_covariance_cholesky(data, reg=0.1):
    """ä½¿ç”¨ Cholesky åˆ†è§£çš„åæ–¹å·®æ­£åˆ™åŒ–"""
    cov = np.cov(data)
    
    # æ·»åŠ æ­£åˆ™åŒ–é¡¹
    cov[np.diag_indices_from(cov)] += reg
    
    # Cholesky åˆ†è§£ (è¦æ±‚æ­£å®š)
    try:
        L = np.linalg.cholesky(cov)
    except np.linalg.LinAlgError:
        # å¦‚æžœå¤±è´¥ï¼Œä½¿ç”¨ SVD æ›¿ä»£
        U, s, Vh = np.linalg.svd(cov)
        L = U @ np.diag(np.sqrt(s))
    
    return L
```

---

#### 3.2 QR åˆ†è§£

```python
# ä½ç½®: mne/preprocessing/_csd.py
def _orthogonalize_vectors(X):
    """ä½¿ç”¨ QR åˆ†è§£æ­£äº¤åŒ–åˆ—å‘é‡"""
    Q, R = np.linalg.qr(X)
    
    # Q çš„åˆ—å‘é‡æ˜¯æ­£äº¤çš„
    # X â‰ˆ Q @ R
    
    return Q
```

**åº”ç”¨**: CSD (Current Source Density) è®¡ç®—

---

## FFT åº”ç”¨åœºæ™¯

### 1. FIR æ»¤æ³¢å™¨å®žçŽ°

**ä½ç½®**: `mne/filter.py`

**åŽŸç†**: æ—¶åŸŸå·ç§¯ = é¢‘åŸŸä¹˜æ³•

```python
def fir_filter_fft(data, h, n_fft):
    """ä½¿ç”¨ FFT å®žçŽ° FIR æ»¤æ³¢"""
    # h: æ»¤æ³¢å™¨ç³»æ•° (impulse response)
    # n_fft: FFT é•¿åº¦
    
    # 1. é›¶å¡«å……æ»¤æ³¢å™¨ç³»æ•°
    h_padded = np.zeros(n_fft)
    h_padded[:len(h)] = h
    
    # 2. FFT
    H = np.fft.rfft(h_padded)        # æ»¤æ³¢å™¨é¢‘åŸŸè¡¨ç¤º
    X = np.fft.rfft(data, n=n_fft)   # æ•°æ®é¢‘åŸŸè¡¨ç¤º
    
    # 3. é¢‘åŸŸä¹˜æ³•
    Y = X * H
    
    # 4. é€† FFT
    y = np.fft.irfft(Y, n=n_fft)
    
    # 5. æå–æœ‰æ•ˆéƒ¨åˆ† (åŽ»é™¤ padding)
    y = y[:len(data)]
    
    return y
```

**ä¼˜åŠ¿**:
- æ—¶åŸŸå·ç§¯: O(N * M)
- FFT å·ç§¯: O(N log N)

---

### 2. æ—¶é¢‘åˆ†æž (STFT)

**ä½ç½®**: `mne/time_frequency/_stft.py`

```python
def stft(x, wsize, tstep):
    """çŸ­æ—¶å‚…é‡Œå¶å˜æ¢"""
    # x: ä¿¡å·, shape (n_times,)
    # wsize: çª—å£å¤§å°
    # tstep: æ—¶é—´æ­¥é•¿
    
    n_times = len(x)
    n_freqs = wsize // 2 + 1
    n_windows = (n_times - wsize) // tstep + 1
    
    # åˆå§‹åŒ–è¾“å‡º
    X = np.zeros((n_freqs, n_windows), dtype=np.complex128)
    
    # æ±‰å®çª—
    window = np.hanning(wsize)
    
    # æ»‘åŠ¨çª—å£ FFT
    for i in range(n_windows):
        start = i * tstep
        end = start + wsize
        
        # åŠ çª— + FFT
        x_windowed = x[start:end] * window
        X[:, i] = np.fft.rfft(x_windowed)
    
    return X
```

**åº”ç”¨**:
- **é¢‘è°±å›¾**: `mne.viz.plot_epochs_psd_topomap()`
- **æ—¶é¢‘åˆ†è§£**: `mne.time_frequency.tfr_morlet()`

---

### 3. Hilbert å˜æ¢

**ä½ç½®**: `mne/preprocessing/ctps_.py`

```python
def hilbert_transform(data):
    """ä½¿ç”¨ FFT å®žçŽ° Hilbert å˜æ¢"""
    from scipy.signal import hilbert
    
    # SciPy å†…éƒ¨å®žçŽ°ä¹Ÿä½¿ç”¨ FFT
    analytic_signal = hilbert(data, axis=-1)
    
    # æå–ç›¸ä½
    phase = np.angle(analytic_signal)
    
    # æå–å¹…åº¦åŒ…ç»œ
    amplitude = np.abs(analytic_signal)
    
    return phase, amplitude
```

**åº”ç”¨**: CTPS (Cross-Trial Phase Statistics) - ç›¸ä½ä¸€è‡´æ€§åˆ†æž

---

## æ•°å­¦å‡½æ•°ä½¿ç”¨

### 1. ä¸‰è§’å‡½æ•°

```python
# ä½ç½®: mne/transforms.py
def rotation3d(x=0, y=0, z=0):
    """3D æ—‹è½¬çŸ©é˜µ"""
    cos_x, sin_x = np.cos(x), np.sin(x)
    cos_y, sin_y = np.cos(y), np.sin(y)
    cos_z, sin_z = np.cos(z), np.sin(z)
    
    R = np.array([
        [cos_y*cos_z, -cos_x*sin_z + sin_x*sin_y*cos_z,  ...],
        [cos_y*sin_z,  cos_x*cos_z + sin_x*sin_y*sin_z,  ...],
        [-sin_y,       sin_x*cos_y,                       ...]
    ])
    
    return R
```

---

### 2. ç»Ÿè®¡å‡½æ•°

```python
# ä½ç½®: mne/utils/numerics.py
def compute_corr(x, y):
    """è®¡ç®— Pearson ç›¸å…³ç³»æ•°"""
    # x: shape (n_features,)
    # y: shape (n_samples, n_features)
    
    # ä¸­å¿ƒåŒ–
    x_centered = x - x.mean()
    y_centered = y - y.mean(axis=-1, keepdims=True)
    
    # ç›¸å…³ç³»æ•°
    corr = (y_centered @ x_centered) / (
        np.sqrt((y_centered ** 2).sum(axis=-1)) * 
        np.sqrt((x_centered ** 2).sum())
    )
    
    return corr
```

---

### 3. æ•°å€¼ç¨³å®šæ€§æŠ€å·§

```python
# ä½ç½®: mne/utils/numerics.py
def _log_sum_exp(x, axis=None):
    """æ•°å€¼ç¨³å®šçš„ log(sum(exp(x)))"""
    x_max = x.max(axis=axis, keepdims=True)
    
    # log(sum(exp(x))) = log(sum(exp(x - x_max) * exp(x_max)))
    #                  = log(sum(exp(x - x_max))) + x_max
    out = np.log(np.sum(np.exp(x - x_max), axis=axis)) + x_max.squeeze()
    
    return out
```

**åº”ç”¨**: é¿å…ä¸Šæº¢/ä¸‹æº¢

---

## æ€§èƒ½ä¼˜åŒ–æŠ€å·§

### 1. å¹¿æ’­ (Broadcasting)

```python
# ä½Žæ•ˆ: ä½¿ç”¨å¾ªçŽ¯
result = np.zeros((n_epochs, n_channels, n_times))
for i in range(n_epochs):
    for j in range(n_channels):
        result[i, j, :] = data[i, j, :] - baseline[j]

# é«˜æ•ˆ: ä½¿ç”¨å¹¿æ’­
baseline = data.mean(axis=2, keepdims=True)  # shape: (n_epochs, n_channels, 1)
result = data - baseline  # è‡ªåŠ¨å¹¿æ’­
```

---

### 2. é¢„åˆ†é…æ•°ç»„

```python
# ä½Žæ•ˆ: åŠ¨æ€å¢žé•¿
result = []
for i in range(n_samples):
    result.append(process(data[i]))
result = np.array(result)

# é«˜æ•ˆ: é¢„åˆ†é…
result = np.empty((n_samples, output_size))
for i in range(n_samples):
    result[i] = process(data[i])
```

---

### 3. åŽŸåœ°æ“ä½œ (In-place)

```python
# åˆ›å»ºæ–°æ•°ç»„
data_norm = data / np.linalg.norm(data, axis=-1, keepdims=True)

# åŽŸåœ°ä¿®æ”¹ (èŠ‚çœå†…å­˜)
data /= np.linalg.norm(data, axis=-1, keepdims=True)
```

---

### 4. einsum ä¼˜åŒ–

```python
# ä½Žæ•ˆ: å¤šæ­¥çŸ©é˜µä¹˜æ³•
result = (A @ B @ C.T)

# é«˜æ•ˆ: ä¸€æ¬¡ einsum
result = np.einsum('ij,jk,lk->il', A, B, C)
```

**ä½•æ—¶ä½¿ç”¨ einsum**:
- âœ… å¤æ‚çš„å¼ é‡æ”¶ç¼©
- âœ… è‡ªå®šä¹‰æ±‚å’Œè·¯å¾„
- âŒ ç®€å•çš„çŸ©é˜µä¹˜æ³• (`@` æ›´å¿«)

---

## ä»£ç ç¤ºä¾‹

### ç¤ºä¾‹ 1: Epoch å¹³å‡ (Evoked)

```python
# ä½ç½®: mne/epochs.py
def average(epochs):
    """è®¡ç®— epochs å¹³å‡"""
    data = epochs.get_data()  # (n_epochs, n_channels, n_times)
    
    # NumPy å¹³å‡
    evoked_data = data.mean(axis=0)  # (n_channels, n_times)
    
    return evoked_data
```

---

### ç¤ºä¾‹ 2: åŸºçº¿æ ¡æ­£

```python
# ä½ç½®: mne/baseline.py
def rescale(data, times, baseline, mode='mean'):
    """åŸºçº¿æ ¡æ­£"""
    # æ‰¾åˆ°åŸºçº¿æ—¶é—´ç´¢å¼•
    bmin, bmax = baseline
    baseline_mask = (times >= bmin) & (times <= bmax)
    
    if mode == 'mean':
        # å‡åŽ»åŸºçº¿å‡å€¼
        baseline_mean = data[..., baseline_mask].mean(axis=-1, keepdims=True)
        data -= baseline_mean
        
    elif mode == 'ratio':
        # é™¤ä»¥åŸºçº¿å‡å€¼
        baseline_mean = data[..., baseline_mask].mean(axis=-1, keepdims=True)
        data /= baseline_mean
        
    elif mode == 'zscore':
        # Z-score æ ‡å‡†åŒ–
        baseline_mean = data[..., baseline_mask].mean(axis=-1, keepdims=True)
        baseline_std = data[..., baseline_mask].std(axis=-1, keepdims=True)
        data = (data - baseline_mean) / baseline_std
    
    return data
```

---

### ç¤ºä¾‹ 3: PCA é™ç»´

```python
# ä½ç½®: mne/utils/numerics.py
class _PCA:
    """ç®€åŒ–çš„ PCA å®žçŽ°"""
    
    def fit(self, X):
        """æ‹Ÿåˆ PCA"""
        # X: (n_samples, n_features)
        
        # ä¸­å¿ƒåŒ–
        self.mean_ = X.mean(axis=0)
        X_centered = X - self.mean_
        
        # åæ–¹å·®çŸ©é˜µ
        cov = (X_centered.T @ X_centered) / (X.shape[0] - 1)
        
        # ç‰¹å¾å€¼åˆ†è§£
        eigvals, eigvecs = np.linalg.eigh(cov)
        
        # é™åºæŽ’åº
        idx = eigvals.argsort()[::-1]
        self.explained_variance_ = eigvals[idx]
        self.components_ = eigvecs[:, idx].T  # (n_components, n_features)
        
    def transform(self, X, n_components=None):
        """è½¬æ¢æ•°æ®"""
        X_centered = X - self.mean_
        X_pca = X_centered @ self.components_[:n_components].T
        return X_pca
```

---

## æ€»ç»“

### NumPy åœ¨ MNE ä¸­çš„é‡è¦æ€§

| ç»´åº¦ | è¯„åˆ† | è¯´æ˜Ž |
|------|------|------|
| **æ•°æ®å­˜å‚¨** | â­â­â­â­â­ | æ‰€æœ‰æ•°æ®å¯¹è±¡çš„åº•å±‚ |
| **æ•°å­¦è¿ç®—** | â­â­â­â­â­ | æ ¸å¿ƒè®¡ç®—å¼•æ“Ž |
| **çº¿æ€§ä»£æ•°** | â­â­â­â­â­ | SVD, ç‰¹å¾å€¼, çŸ©é˜µè¿ç®— |
| **FFT** | â­â­â­â­â­ | é¢‘åŸŸåˆ†æžã€æ»¤æ³¢ |
| **æµ‹è¯•** | â­â­â­â­â­ | numpy.testing è¦†ç›–æ‰€æœ‰æµ‹è¯• |
| **æ€§èƒ½å½±å“** | â­â­â­â­â­ | BLAS/LAPACK ä¼˜åŒ–è‡³å…³é‡è¦ |

---

### å…³é”®è¦ç‚¹

1. **NumPy æ˜¯ MNE çš„åŸºçŸ³** - æ— æ³•æ›¿ä»£
2. **æ•°ç»„æ“ä½œæ¨¡å¼** - å¹¿æ’­ã€å‘é‡åŒ–ã€é¿å…å¾ªçŽ¯
3. **çº¿æ€§ä»£æ•°** - SVD å’Œç‰¹å¾å€¼åˆ†è§£æ˜¯æ ¸å¿ƒ
4. **FFT åº”ç”¨å¹¿æ³›** - æ»¤æ³¢ã€æ—¶é¢‘åˆ†æžã€é‡é‡‡æ ·
5. **æ€§èƒ½å…³é”®** - å†…å­˜å¸ƒå±€ã€é¢„åˆ†é…ã€åŽŸåœ°æ“ä½œ

---

**è¿”å›ž**: [ä¾èµ–åˆ†æžæ€»è§ˆ](dependency-analysis-overview.md)  
**ä¸‹ä¸€æ­¥**: [SciPy ä¾èµ–åˆ†æž](dependency-scipy.md)
